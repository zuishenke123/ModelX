{
      "_comment": "Note: It does not include operators from the xx.nn.functional.xx series!",
      "torch.manual_seed": {
            "Matcher": "DirectMatcher",
            "target_api": "paddle.seed",
            "Classification": 0
      },
      "torch.nn.Conv1d": {
            "Matcher": "DirectMatcher",
            "Classification": 1,
            "params_change": {
                  "bias": "bias_attr"
            }
      },
      "torch.nn.Conv2d": {
            "Matcher": "DirectMatcher",
            "Classification": 1,
            "params_change": {
                  "bias": "bias_attr"
            }
      },
      "torch.nn.Conv3d": {
            "Matcher": "DirectMatcher",
            "Classification": 1,
            "params_change": {
                  "bias": "bias_attr"
            }
      },
      "torch.nn.ConvTranspose1d": {
            "Matcher": "DirectMatcher",
            "Classification": 1,
            "params_change": {
                  "bias": "bias_attr"
            },
            "target_api":"paddle.nn.Conv1DTranspose"
      },
      "torch.nn.ConvTranspose2d": {
            "Matcher": "DirectMatcher",
            "Classification": 1,
            "params_change": {
                  "bias": "bias_attr"
            },
            "target_api":"paddle.nn.Conv2DTranspose"
      },
      "torch.nn.ConvTranspose3d": {
            "Matcher": "DirectMatcher",
            "Classification": 1,
            "params_change": {
                  "bias": "bias_attr"
            },
            "target_api":"paddle.nn.Conv3DTranspose"
      },
      "torch.nn.Fold": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.nn.PairwiseDistance": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "params_change": {
                  "eps": "epsilon"
            }
      },
      "torch.nn.CosineSimilarity": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "params_change": {
                  "dim": "axis"
            }
      },
      "torch.nn.ELU": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.nn.CELU": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.nn.GELU": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "default_kwargs": {
                  "approximate": "False"
            }
      },
      "torch.nn.GLU": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "params_change": {
                  "dim": "axis"
            }
      },
      "torch.nn.Hardshrink": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "params_change": {
                  "lambd": "threshold"
            }
      },
      "torch.nn.Hardsigmoid": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.nn.Hardswish": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.nn.Hardtanh": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "paddle.nn.Hardtanh": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "params_change": {
                  "min_val": "min",
                  "max_val": "max"
            }
      },
      "torch.nn.LeakyReLU": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.nn.LogSigmoid": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "params_change": {
                  "dim": "axis"
            }
      },
      "torch.nn.PReLU": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "paddle.nn.RReLU": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.nn.ReLU": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.nn.ReLU6": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.nn.SELU": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.nn.Sigmoid": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.nn.SiLU": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.nn.Softmax": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "params_change": {
                  "dim": "axis"
            }
      },
      "torch.nn.Softplus": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.nn.Softshrink": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "params_change": {
                  "lambd": "threshold"
            }
      },
      "torch.nn.Softsign": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.nn.Mish": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.nn.Tanh": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.nn.Tanhshrink": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.nn.ParameterList": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.nn.ModuleDict": {
            "Matcher": "DirectMatcher",
            "target_api": "paddle.nn.LayerDict",
            "Classification": 0,
            "params_change": {
                  "modules": "sublayers"
            }
      },
      "torch.nn.ModuleList": {
            "Matcher": "DirectMatcher",
            "target_api": "paddle.nn.LayerList",
            "Classification": 0,
            "params_change": {
                  "modules": "sublayers"
            }
      },
      "torch.nn.Dropout2d": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.nn.Dropout3d": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.nn.AlphaDropout": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.nn.Linear": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "params_change": {
                  "bias": "bias_attr"
            }
      },
      "torch.nn.Bilinear": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "params_change": {
                  "bias": "bias_attr"
            }
      },
      "torch.nn.Identity": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.nn.L1Loss": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.nn.MSELoss": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.nn.CrossEntropyLoss": {
            "Matcher": "FuncParamMatcher",
            "Classification": 1,
            "variantCode": [
                  {
                        "param": "label_smoothing",
                        "operatorSequence": [
                              {
                                    "level": "C underlying library",
                                    "function": {
                                          "CPU": "HardLabelCrossEntropyCPUFunctorImpl",
                                          "GPU": "CrossEntropyKernel"
                                    },
                                    "namespace": {
                                          "CPU": ["phi", "funcs"],
                                          "GPU": ["phi", "funcs"]
                                    },
                                    "backend": {
                                          "CPU":{
                                                "headers": [
                                                      "#include \"paddle/phi/kernels/funcs/cross_entropy.h\"",
                                                      "#include \"paddle/phi/backends/cpu/cpu_context.h\"",
                                                      "#include \"paddle/phi/core/utils/data_type.h\""
                                                ],
                                                "funcContext": [],
                                                "sourceCode": "template <typename T>\nstruct HardLabelCrossEntropyCPUFunctorImpl {\n  HardLabelCrossEntropyCPUFunctorImpl(phi::DenseTensor* out,\n                                      const phi::DenseTensor* prob,\n                                      const phi::DenseTensor* labels,\n                                      const int ignore_index,\n                                      const int axis_dim)\n      : out_(out),\n        prob_(prob),\n        labels_(labels),\n        ignore_index_(ignore_index),\n        axis_dim_(axis_dim) {}\n\n  template <typename U>\n  void apply() const {\n    const int batch_size = prob_->dims()[0];\n    const int num_classes = prob_->dims()[1];\n    const int num_remain = num_classes / axis_dim_;\n\n    const T* prob_data = prob_->template data<T>();\n    T* loss_data = out_->template data<T>();\n\n    const auto* label_data = labels_->template data<U>();\n    for (int i = 0; i < batch_size; ++i) {\n      for (int j = 0; j < num_remain; j++) {\n        int lbl = static_cast<int>(label_data[i * num_remain + j]);\n        if (lbl != ignore_index_) {\n          PADDLE_ENFORCE_GE(\n              lbl,\n              0,\n              phi::errors::OutOfRange(\"label value should >= 0 when label \"\n                                      \"value(%f) not equal to ignore_index(%f)\",\n                                      lbl,\n                                      ignore_index_));\n          PADDLE_ENFORCE_LT(\n              lbl,\n              axis_dim_,\n              phi::errors::OutOfRange(\n                  \"label value should less than the shape of axis dimension \"\n                  \"when label value(%f) not equal to ignore_index(%f), But \"\n                  \"received label value as %ld and shape of axis dimension \"\n                  \"is %d\",\n                  lbl,\n                  ignore_index_,\n                  lbl,\n                  axis_dim_));\n        }\n        int index = i * num_classes + lbl * num_remain + j;\n        int loss_idx = i * num_remain + j;\n        loss_data[loss_idx] =\n            lbl == ignore_index_\n                ? 0\n                : -phi::funcs::TolerableValue<T>()(std::log(prob_data[index]));\n      }\n    }\n  }\n\n private:\n  phi::DenseTensor* out_;\n  const phi::DenseTensor* prob_;\n  const phi::DenseTensor* labels_;\n  const int ignore_index_;\n  const int axis_dim_;\n};",
                                                "sequence": [
                                                      {
                                                            "class": "add",
                                                            "loc": ["int loss_idx = i * num_remain + j;\n"],
                                                            "code": [
                                                                  "T ret = 0;",
                                                                  "for (int k = 0; k < num_classes; ++k) {",
                                                                  "ret += -phi::funcs::TolerableValue<T>()(std::log(prob_data[i * num_classes + k * num_remain + j]));",
                                                                  "}",
                                                                  "ret /= num_classes;"
                                                            ]
                                                      },
                                                      {
                                                            "class": "modify",
                                                            "loc": ["-phi::funcs::TolerableValue<T>()(std::log(prob_data[index]))\n"],
                                                            "code": [
                                                                  {
                                                                        "-phi::funcs::TolerableValue<T>()(std::log(prob_data[index]));": " (1 - label_smoothin) * -phi::funcs::TolerableValue<T>()(std::log(prob_data[index])) + ret * label_smoothing;"
                                                                  }
                                                            ]
                                                      }
                                                ]
                                          },
                                          "GPU": {
                                                "headers": [
                                                      "#include \"paddle/phi/kernels/funcs/cross_entropy.h\"",
                                                      "#include \"paddle/phi/backends/gpu/gpu_context.h\"",
                                                      "#include \"paddle/phi/backends/gpu/gpu_device_function.h\"",
                                                      "#include \"paddle/phi/backends/gpu/gpu_dnn.h\"",
                                                      "#include \"paddle/phi/backends/gpu/gpu_primitives.h\"",
                                                      "#include \"paddle/phi/core/utils/data_type.h\"",
                                                      "#include \"paddle/phi/kernels/funcs/math.h\""
                                                ],
                                                "funcContext": [],
                                                "sourceCode": "template <typename T, typename LabelT>\n__global__ void CrossEntropyKernel(T* Y,\n                                   const T* X,\n                                   const LabelT* label,\n                                   const int N,\n                                   const int D,\n                                   const int ignore_index) {\n  CUDA_KERNEL_LOOP(i, N) {\n    auto lbl = static_cast<int64_t>(label[i]);\n    PADDLE_ENFORCE(lbl >= 0 && lbl < D || lbl == ignore_index,\n                   \"The value of label[%d] expected >= 0 and < %ld, or == %ld, \"\n                   \"but got %ld. Please check input value.\",\n                   i,\n                   D,\n                   ignore_index,\n                   lbl);\n    Y[i] = ignore_index == lbl ? static_cast<T>(0)\n                               : -phi::funcs::TolerableValue<T>()(\n                                     phi::funcs::real_log(X[i * D + lbl]));\n  }\n}",
                                                "sequence": [
                                                      {
                                                            "class": "add",
                                                            "loc": ["CUDA_KERNEL_LOOP(i, N) {"],
                                                            "code": [
                                                                  "T ret = 0;",
                                                                  "for (int j = 0; j < D; ++j) {",
                                                                  "ret += -phi::funcs::TolerableValue<T>()(phi::funcs::real_log(X[i * D + j]));",
                                                                  "}",
                                                                  "ret /= D;"
                                                            ]
                                                      },
                                                      {
                                                            "class": "modify",
                                                            "loc": ["Y[i] = ignore_index == lbl ? static_cast<T>(0)\n                               : -phi::funcs::TolerableValue<T>()(\n                                     phi::funcs::real_log(X[i * D + lbl]));"],
                                                            "code": [
                                                                  {
                                                                        "-phi::funcs::TolerableValue<T>()(\n                                     phi::funcs::real_log(X[i * D + lbl]))": "(1 - label_smoothing) * (-phi::funcs::TolerableValue<T>()(phi::funcs::real_log(X[i * D + lbl]))) + label_smoothing * ret"
                                                                  }
                                                            ]
                                                      }

                                                ]
                                          }
                                    }
                              }
                        ]
                  }
            ]
      },
      "torch.nn.CTCLoss": {
            "Matcher": "FuncParamMatcher",
            "Classification": 1,
            "variantCode": [
                  {
                        "param": "zero_infinity",
                        "value": "True",
                        "operatorSequence": [
                              {
                                    "level": "C underlying library",
                                    "function": {
                                          "CPU": "WarpctcGradKernel",
                                          "GPU": "WarpctcGradKernel"
                                    },
                                     "namespace": {
                                          "CPU": ["phi"],
                                          "GPU": ["phi"]
                                    },
                                    "backend": {
                                          "CPU":{
                                                "headers": [
                                                      "#include <vector>",
                                                      "#include \"paddle/phi/backends/dynload/warpctc.h\"",
                                                      "#include \"paddle/phi/core/dense_tensor.h\"",
                                                      "#include \"paddle/phi/kernels/empty_kernel.h\"",
                                                      "#include \"paddle/phi/kernels/funcs/eigen/common.h\"",
                                                      "#include \"paddle/phi/kernels/funcs/math_function.h\"",
                                                      "#include \"paddle/phi/kernels/funcs/sequence_padding.h\"",
                                                      "#include \"paddle/phi/kernels/funcs/sequence_scale.h\"",
                                                      "#include \"paddle/utils/optional.h\""
                                                ],
                                                "funcContext": [],
                                                "sourceCode": "template <typename T, typename Context>\nvoid WarpctcGradKernel(const Context& dev_ctx,\n                       const DenseTensor& logits UNUSED,\n                       const paddle::optional<DenseTensor>& logits_length,\n                       const DenseTensor& warpctcgrad,\n                       const DenseTensor& loss_grad,\n                       int blank UNUSED,\n                       bool norm_by_times,\n                       DenseTensor* logits_grad) {\n  dev_ctx.template Alloc<T>(logits_grad);\n\n  if (logits_length.is_initialized()) {\n    int max_seq_length = warpctcgrad.dims()[0];  // Tmax\n    int num_sequences = warpctcgrad.dims()[1];   // B\n    int seq_width = warpctcgrad.dims()[2];       // D\n\n    // B\n    auto logits_len_e = EigenTensor<int64_t, 1>::From(*logits_length);\n    // (B, 1)\n    auto loss_grad_e = EigenTensor<T, 2>::From(loss_grad);\n    // (T, B, D)\n    auto warpctcgrad_e = EigenTensor<T, 3>::From(warpctcgrad);\n\n    auto logits_grad_e = EigenTensor<T, 3>::From(*logits_grad);\n\n    Eigen::DSizes<int, 3> grad_shape(1, num_sequences, 1);\n    Eigen::DSizes<int, 3> bcast(max_seq_length, 1, seq_width);\n    auto logits_g =\n        warpctcgrad_e * loss_grad_e.reshape(grad_shape).broadcast(bcast).eval();\n\n    auto* place = dev_ctx.eigen_device();\n    if (norm_by_times) {\n      auto scales = logits_len_e.cast<T>()\n                        .inverse()\n                        .reshape(grad_shape)\n                        .broadcast(bcast)\n                        .eval();\n      logits_grad_e.device(*place) = logits_g * scales;\n    } else {\n      logits_grad_e.device(*place) = logits_g;\n    }\n  } else {\n    phi::funcs::UnpaddingLoDTensorFunctor<Context, T>()(\n        dev_ctx,\n        warpctcgrad,\n        logits_grad,\n        -1,\n        0,\n        norm_by_times,\n        phi::funcs::kLengthBatchWidth);\n\n    const T* loss_grad_data = loss_grad.data<T>();\n    phi::funcs::ScaleLoDTensorFunctor<Context, T>()(\n        dev_ctx, loss_grad_data, logits_grad);\n  }\n}",
                                                "sequence": [
                                                      {
                                                            "class": "add",
                                                            "loc": ["auto logits_g =\n        warpctcgrad_e * loss_grad_e.reshape(grad_shape).broadcast(bcast).eval();"],
                                                            "code": [
                                                                  "auto mask = loss_grad_e != std::numeric_limits<T>::infinity();",
                                                                  "logits_g = logits_g * mask.template cast<T>();"
                                                            ]
                                                      },
                                                      {
                                                            "class": "modify",
                                                            "loc": ["phi::funcs::ScaleLoDTensorFunctor<Context, T>()(\n        dev_ctx, loss_grad_data, logits_grad);"],
                                                            "code": [
                                                                  {
                                                                        "phi::funcs::ScaleLoDTensorFunctor<Context, T>()(\n        dev_ctx, loss_grad_data, logits_grad);": " phi::funcs::ScaleLoDTensorFunctor<Context, T>()(\n          dev_ctx, loss_grad_data, logits_grad);"
                                                                  }
                                                            ]
                                                      }
                                                ]
                                          },
                                          "GPU":{
                                                "headers": [
                                                      "#include <vector>",
                                                      "#include \"paddle/phi/backends/dynload/warpctc.h\"",
                                                      "#include \"paddle/phi/core/dense_tensor.h\"",
                                                      "#include \"paddle/phi/kernels/empty_kernel.h\"",
                                                      "#include \"paddle/phi/kernels/funcs/eigen/common.h\"",
                                                      "#include \"paddle/phi/kernels/funcs/math_function.h\"",
                                                      "#include \"paddle/phi/kernels/funcs/sequence_padding.h\"",
                                                      "#include \"paddle/phi/kernels/funcs/sequence_scale.h\"",
                                                      "#include \"paddle/utils/optional.h\""
                                                ],
                                                "funcContext": [],
                                                "sourceCode": "template <typename T, typename Context>\nvoid WarpctcGradKernel(const Context& dev_ctx,\n                       const DenseTensor& logits UNUSED,\n                       const paddle::optional<DenseTensor>& logits_length,\n                       const DenseTensor& warpctcgrad,\n                       const DenseTensor& loss_grad,\n                       int blank UNUSED,\n                       bool norm_by_times,\n                       DenseTensor* logits_grad) {\n  dev_ctx.template Alloc<T>(logits_grad);\n\n  if (logits_length.is_initialized()) {\n    int max_seq_length = warpctcgrad.dims()[0];  // Tmax\n    int num_sequences = warpctcgrad.dims()[1];   // B\n    int seq_width = warpctcgrad.dims()[2];       // D\n\n    // B\n    auto logits_len_e = EigenTensor<int64_t, 1>::From(*logits_length);\n    // (B, 1)\n    auto loss_grad_e = EigenTensor<T, 2>::From(loss_grad);\n    // (T, B, D)\n    auto warpctcgrad_e = EigenTensor<T, 3>::From(warpctcgrad);\n\n    auto logits_grad_e = EigenTensor<T, 3>::From(*logits_grad);\n\n    Eigen::DSizes<int, 3> grad_shape(1, num_sequences, 1);\n    Eigen::DSizes<int, 3> bcast(max_seq_length, 1, seq_width);\n    auto logits_g =\n        warpctcgrad_e * loss_grad_e.reshape(grad_shape).broadcast(bcast).eval();\n\n    auto* place = dev_ctx.eigen_device();\n    if (norm_by_times) {\n      auto scales = logits_len_e.cast<T>()\n                        .inverse()\n                        .reshape(grad_shape)\n                        .broadcast(bcast)\n                        .eval();\n      logits_grad_e.device(*place) = logits_g * scales;\n    } else {\n      logits_grad_e.device(*place) = logits_g;\n    }\n  } else {\n    phi::funcs::UnpaddingLoDTensorFunctor<Context, T>()(\n        dev_ctx,\n        warpctcgrad,\n        logits_grad,\n        -1,\n        0,\n        norm_by_times,\n        phi::funcs::kLengthBatchWidth);\n\n    const T* loss_grad_data = loss_grad.data<T>();\n    phi::funcs::ScaleLoDTensorFunctor<Context, T>()(\n        dev_ctx, loss_grad_data, logits_grad);\n  }\n}",
                                                "sequence": [
                                                      {
                                                            "class": "add",
                                                            "loc": ["auto logits_g =\n        warpctcgrad_e * loss_grad_e.reshape(grad_shape).broadcast(bcast).eval();"],
                                                            "code": [
                                                                  "auto mask = loss_grad_e != std::numeric_limits<T>::infinity();",
                                                                  "logits_g = logits_g * mask.template cast<T>();"
                                                            ]
                                                      },
                                                      {
                                                            "class": "modify",
                                                            "loc": ["phi::funcs::ScaleLoDTensorFunctor<Context, T>()(\n        dev_ctx, loss_grad_data, logits_grad);"],
                                                            "code": [
                                                                  {
                                                                        "phi::funcs::ScaleLoDTensorFunctor<Context, T>()(\n        dev_ctx, loss_grad_data, logits_grad);": " phi::funcs::ScaleLoDTensorFunctor<Context, T>()(\n          dev_ctx, loss_grad_data, logits_grad);"
                                                                  }
                                                            ]
                                                      }
                                                ]
                                          }
                                    }
                              }
                        ]
                  }
            ]
      },
      "torch.nn.NLLLoss": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.nn.PoissonNLLLoss": {
            "Matcher": "FuncParamMatcher",
            "Classification": 1,
            "params_change": {
                  "eps": "epsilon"
            },
            "params_deprecation": [
                  "size_average",
                  "reduce"
            ]
      },
      "torch.nn.GaussianNLLLoss": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "params_change": {
                  "eps": "epsilon"
            }
      },
      "torch.nn.KLDivLoss": {
            "Matcher": "FuncParamMatcher",
            "Classification": 1,
            "variantCode": [
                  {
                        "param": "log_target",
                        "value": "True",
                        "operatorSequence": [
                              {
                                    "level": "C underlying library",
                                    "function": {
                                          "CPU": "KLDivLossKernel",
                                          "GPU": "KLDivLossKernel"
                                    },
                                     "namespace": {
                                          "CPU": ["phi"],
                                          "GPU": ["phi"]
                                    },
                                    "backend": {
                                          "CPU":{
                                                "headers": [
                                                      "#include <string>",
                                                      "#include \"paddle/phi/backends/cpu/cpu_context.h\"",
                                                      "#include \"paddle/phi/core/dense_tensor.h\"",
                                                      "#include \"paddle/phi/core/hostdevice.h\"",
                                                      "#include \"paddle/phi/kernels/funcs/eigen/common.h\""
                                                ],
                                                "funcContext": [],
                                                "sourceCode": "template <typename T, typename Context>\nvoid KLDivLossKernel(const Context& dev_ctx,\n                     const DenseTensor& x,\n                     const DenseTensor& label,\n                     const std::string& reduction,\n                     DenseTensor* out) {\n  auto& place = *(dev_ctx.eigen_device());\n  auto* input = &x;\n  auto* target = &label;\n  auto* loss = out;\n\n  const int n = input->dims()[0];\n  dev_ctx.template Alloc<T>(loss);\n\n  auto input_t = phi::EigenVector<T>::Flatten(*input);\n  auto target_t = phi::EigenVector<T>::Flatten(*target);\n  auto loss_t = phi::EigenVector<T>::Flatten(*loss);\n  auto output = target_t.binaryExpr(input_t, KLDivLossForward<T>());\n  if (\"none\" == reduction) {\n    loss_t.device(place) = output;\n  } else if (\"batchmean\" == reduction) {\n    auto output_sum = output.sum();\n    if (n > 0) {\n      loss_t.device(place) = output_sum / output_sum.constant(n);\n    } else {\n      loss_t.device(place) = output_sum;\n    }\n  } else if (\"mean\" == reduction) {\n    loss_t.device(place) = output.mean();\n  } else if (\"sum\" == reduction) {\n    loss_t.device(place) = output.sum();\n  }\n}",
                                                "sequence": [
                                                      {
                                                            "class": "modify",
                                                            "loc": ["auto output = target_t.binaryExpr(input_t, KLDivLossForward<T>());"],
                                                            "code": [
                                                                  {
                                                                        "auto output = target_t.binaryExpr(input_t, KLDivLossForward<T>());": "auto output = target_t.exp() * (target_t - input_t);"
                                                                  }
                                                            ]
                                                      }
                                                ]
                                          },
                                          "GPU":{
                                                "headers": [
                                                      "#include <string>",
                                                      "#include \"paddle/phi/backends/cpu/cpu_context.h\"",
                                                      "#include \"paddle/phi/core/dense_tensor.h\"",
                                                      "#include \"paddle/phi/core/hostdevice.h\"",
                                                      "#include \"paddle/phi/kernels/funcs/eigen/common.h\""
                                                ],
                                                "funcContext": [],
                                                "sourceCode": "template <typename T, typename Context>\nvoid KLDivLossKernel(const Context& dev_ctx,\n                     const DenseTensor& x,\n                     const DenseTensor& label,\n                     const std::string& reduction,\n                     DenseTensor* out) {\n  auto& place = *(dev_ctx.eigen_device());\n  auto* input = &x;\n  auto* target = &label;\n  auto* loss = out;\n\n  const int n = input->dims()[0];\n  dev_ctx.template Alloc<T>(loss);\n\n  auto input_t = phi::EigenVector<T>::Flatten(*input);\n  auto target_t = phi::EigenVector<T>::Flatten(*target);\n  auto loss_t = phi::EigenVector<T>::Flatten(*loss);\n  auto output = target_t.binaryExpr(input_t, KLDivLossForward<T>());\n  if (\"none\" == reduction) {\n    loss_t.device(place) = output;\n  } else if (\"batchmean\" == reduction) {\n    auto output_sum = output.sum();\n    if (n > 0) {\n      loss_t.device(place) = output_sum / output_sum.constant(n);\n    } else {\n      loss_t.device(place) = output_sum;\n    }\n  } else if (\"mean\" == reduction) {\n    loss_t.device(place) = output.mean();\n  } else if (\"sum\" == reduction) {\n    loss_t.device(place) = output.sum();\n  }\n}",
                                                "sequence": [
                                                      {
                                                            "class": "modify",
                                                            "loc": ["auto output = target_t.binaryExpr(input_t, KLDivLossForward<T>());"],
                                                            "code": [
                                                                  {
                                                                        "auto output = target_t.binaryExpr(input_t, KLDivLossForward<T>());": "auto output = target_t.exp() * (target_t - input_t);"
                                                                  }
                                                            ]
                                                      }
                                                ]
                                          }
                                    }
                              }
                        ]
                  }
            ]
      },
      "torch.nn.BCELoss": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.nn.BCEWithLogitsLoss": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.nn.HingeEmbeddingLoss": {
            "Matcher": "FuncParamMatcher",
            "Classification": 1,
            "params_deprecation": [
                  "size_average",
                  "reduce"
            ]
      },
      "torch.nn.MarginRankingLoss": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.nn.MultiLabelSoftMarginLoss": {
            "Matcher": "FuncParamMatcher",
            "Classification": 1,
            "params_deprecation": [
                  "size_average",
                  "reduce"
            ]
      },
      "torch.nn.SmoothL1Loss": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "params_change": {
                  "beta": "delta"
            }
      },
      "torch.nn.SoftMarginLoss": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.nn.CosineEmbeddingLoss": {
            "Matcher": "FuncParamMatcher",
            "Classification": 1,
            "params_deprecation": [
                  "size_average",
                  "reduce"
            ]
      },
      "torch.nn.MultiMarginLoss": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.nn.TripletMarginLoss": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "params_change": {
                  "eps": "epsilon"
            }
      },
      "torch.nn.TripletMarginWithDistanceLoss": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.nn.functional.mse_loss": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.nn.BatchNorm1d": {
            "Matcher": "DirectMatcher",
            "Classification": 1,
            "params_change": {
                  "eps": "epsilon",
                  "track_running_stats": "use_global_stats",
                  "affine": [
                        "weight_attr",
                        "bias_attr"
                  ]
            }
      },
      "torch.nn.BatchNorm2d": {
            "Matcher": "DirectMatcher",
            "Classification": 1,
            "params_change": {
                  "eps": "epsilon",
                  "track_running_stats": "use_global_stats",
                  "affine": [
                        "weight_attr",
                        "bias_attr"
                  ]
            }
      },
      "torch.nn.BatchNorm3d": {
            "Matcher": "DirectMatcher",
            "Classification": 1,
            "params_change": {
                  "eps": "epsilon",
                  "track_running_stats": "use_global_stats",
                  "affine": [
                        "weight_attr",
                        "bias_attr"
                  ]
            }
      },
      "torch.nn.GroupNorm": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "params_change": {
                  "eps": "epsilon",
                  "affine": [
                        "weight_attr",
                        "bias_attr"
                  ]
            }
      },
      "torch.nn.InstanceNorm1d": {
            "Matcher": "FuncParamMatcher",
            "Classification": 0,
            "variantCode": [
                  {
                        "param": "track_running_stats",
                        "value": "False",
                        "operatorSequence": [
                              {
                                    "level": "python underlying library",
                                    "function": "forward",
                                    "sequence": [
                                          {
                                                "class": "modify",
                                                "loc": ["return instance_norm(\n            input,\n            weight=self.scale,\n            bias=self.bias,\n            momentum=self._momentum,\n            eps=self._epsilon,\n            data_format=self._data_format,\n        )"],
                                                "code": [
                                                      {
                                                            "eps=self._epsilon": "eps=self._epsilon, use_input_stats=False,"
                                                      }
                                                ]
                                          }
                                    ]
                              }
                        ]
                  }
            ]

      },
      "torch.nn.InstanceNorm2d": {
            "Matcher": "FuncParamMatcher",
            "Classification": 1,
            "variantCode": [
                  {
                        "param": "track_running_stats",
                        "value": "False",
                        "operatorSequence": [
                              {
                                    "level": "python underlying library",
                                    "function": "forward",
                                    "sequence": [
                                          {
                                                "class": "modify",
                                                "loc": ["return instance_norm(\n            input,\n            weight=self.scale,\n            bias=self.bias,\n            momentum=self._momentum,\n            eps=self._epsilon,\n            data_format=self._data_format,\n        )"],
                                                "code": [
                                                      {
                                                            "eps=self._epsilon": "eps=self._epsilon, use_input_stats=False,"
                                                      }
                                                ]
                                          }
                                    ]
                              }
                        ]
                  }
            ]
      },
      "torch.nn.InstanceNorm3d": {
            "Matcher": "FuncParamMatcher",
            "Classification": 0,
            "variantCode": [
                  {
                        "param": "track_running_stats",
                        "value": "False",
                        "operatorSequence": [
                              {
                                    "level": "python underlying library",
                                    "function": "forward",
                                    "sequence": [
                                          {
                                                "class": "modify",
                                                "loc": ["return instance_norm(\n            input,\n            weight=self.scale,\n            bias=self.bias,\n            momentum=self._momentum,\n            eps=self._epsilon,\n            data_format=self._data_format,\n        )"],
                                                "code": [
                                                      {
                                                            "eps=self._epsilon": "eps=self._epsilon, use_input_stats=False,"
                                                      }
                                                ]
                                          }
                                    ]
                              }
                        ]
                  }
            ]
      },
      "torch.nn.LayerNorm": {
            "Matcher": "DirectMatcher",
            "Classification": 1,
            "params_change": {
                  "eps": "epsilon",
                  "elementwise_affine": [
                        "weight_attr",
                        "bias_attr"
                  ]
            }
      },
      "torch.nn.LocalResponseNorm": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.nn.SyncBatchNorm": {
            "Matcher": "DirectMatcher",
            "Classification": 1,
            "params_change": {
                  "eps": "epsilon",
                  "affine": [
                        "weight_attr",
                        "bias_attr"
                  ],
                  "track_running_stats": "use_global_stats"
            }
      },
      "torch.nn.ZeroPad2d": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.nn.ConstantPad1d": {
            "Matcher": "DirectMatcher",
            "target_api": "paddle.nn.Pad1D",
            "Classification": 4,
            "default_kwargs": {
                  "mode": "constant"
            }
      },
      "torch.nn.ReflectionPad1d": {
            "Matcher": "DirectMatcher",
            "target_api": "paddle.nn.Pad1D",
            "Classification": 4,
            "default_kwargs": {
                  "mode": "reflect"
            }
      },
      "torch.nn.ReplicationPad1d": {
            "Matcher": "DirectMatcher",
            "target_api": "paddle.nn.Pad1D",
            "Classification": 4,
            "default_kwargs": {
                  "mode": "replicate"
            }
      },
      "torch.nn.ConstantPad2d": {
            "Matcher": "DirectMatcher",
            "target_api": "paddle.nn.Pad2D",
            "Classification": 4,
            "default_kwargs": {
                  "mode": "constant"
            }
      },
      "torch.nn.ReflectionPad2d": {
            "Matcher": "DirectMatcher",
            "target_api": "paddle.nn.Pad2D",
            "Classification": 4,
            "default_kwargs": {
                  "mode": "reflect"
            }
      },
      "torch.nn.ReplicationPad2d": {
            "Matcher": "DirectMatcher",
            "target_api": "paddle.nn.Pad2D",
            "Classification": 4,
            "default_kwargs": {
                  "mode": "replicate"
            }
      },
      "torch.nn.ConstantPad3d": {
            "Matcher": "DirectMatcher",
            "target_api": "paddle.nn.Pad3D",
            "Classification": 4,
            "default_kwargs": {
                  "mode": "constant"
            }
      },
      "torch.nn.ReflectionPad3d": {
            "Matcher": "DirectMatcher",
            "target_api": "paddle.nn.Pad3D",
            "Classification": 4,
            "default_kwargs": {
                  "mode": "reflect"
            }
      },
      "torch.nn.ReplicationPad3d": {
            "Matcher": "DirectMatcher",
            "target_api": "paddle.nn.Pad3D",
            "Classification": 4,
            "default_kwargs": {
                  "mode": "replicate"
            }
      },
      "torch.nn.MaxPool1d": {
            "Matcher": "FuncParamMatcher",
            "Classification": 1,
            "params_change": {
                  "return_indices": "return_mask"
            },
            "variantCode": [
                  {
                        "param": "dilation",
                        "operatorSequence": [
                              {
                                    "level": "C underlying library",
                                    "function": {
                                          "CPU": "Pool2dFunctor",
                                          "GPU": "Pool2dFunctor"
                                    },
                                    "namespace": {
                                          "CPU": [
                                                "phi",
                                                "funcs"
                                          ],
                                          "GPU": [
                                                "phi",
                                                "funcs"
                                          ]
                                    },
                                    "backend": {
                                          "CPU":{
                                               "headers": [
                                                     "#include \"paddle/phi/kernels/funcs/pooling.h\"",
                                                     "#include <algorithm>",
                                                     "#include <vector>",
                                                     "#include \"paddle/phi/backends/cpu/cpu_context.h\""
                                               ],
                                                "funcContext": [],
                                                "sourceCode": "template <typename PoolProcess, typename T>\nclass Pool2dFunctor<CPUContext, PoolProcess, T> {\n public:\n  void operator()(const CPUContext& context,\n                  const DenseTensor& input,\n                  const std::vector<int>& ksize,\n                  const std::vector<int>& strides,\n                  const std::vector<int>& paddings,\n                  bool exclusive,\n                  bool adaptive,\n                  DenseTensor* output,\n                  PoolProcess pool_process) {\n    const int batch_size = input.dims()[0];\n    const int input_height = input.dims()[2];\n    const int input_width = input.dims()[3];\n    const int output_channels = output->dims()[1];\n    const int output_height = output->dims()[2];\n    const int output_width = output->dims()[3];\n    const int ksize_height = ksize[0];\n    const int ksize_width = ksize[1];\n    const int stride_height = strides[0];\n    const int stride_width = strides[1];\n    const int padding_height = paddings[0];\n    const int padding_width = paddings[1];\n\n    const int input_stride = input_height * input_width;\n    const int output_stride = output_height * output_width;\n\n    const T* input_data = input.data<T>();\n    T* output_data = context.template Alloc<T>(output);\n\n    int hstart = 0, hend = 1;\n    int wstart = 0, wend = 1;\n    for (int i = 0; i < batch_size; i++) {\n      for (int c = 0; c < output_channels; ++c) {\n        for (int ph = 0; ph < output_height; ++ph) {\n          if (adaptive) {\n            hstart = AdaptStartIndex(ph, input_height, output_height);\n            hend = AdaptEndIndex(ph, input_height, output_height);\n          }\n          for (int pw = 0; pw < output_width; ++pw) {\n            int pool_size = 1;\n            if (adaptive) {\n              wstart = AdaptStartIndex(pw, input_width, output_width);\n              wend = AdaptEndIndex(pw, input_width, output_width);\n            } else {\n              hstart = ph * stride_height - padding_height;\n              wstart = pw * stride_width - padding_width;\n              hend = std::min(hstart + ksize_height,\n                              input_height + padding_height);\n              wend =\n                  std::min(wstart + ksize_width, input_width + padding_width);\n              pool_size = (hend - hstart) * (wend - wstart);\n\n              wstart = std::max(wstart, 0);\n              hstart = std::max(hstart, 0);\n              hend = std::min(hend, input_height);\n              wend = std::min(wend, input_width);\n            }\n\n            T ele = pool_process.initial();\n            for (int h = hstart; h < hend; ++h) {\n              for (int w = wstart; w < wend; ++w) {\n                pool_process.compute(input_data[h * input_width + w], &ele);\n              }\n            }\n            if (exclusive || adaptive) {\n              pool_size = (hend - hstart) * (wend - wstart);\n            }\n\n            pool_process.finalize(static_cast<T>(pool_size), &ele);\n            output_data[ph * output_width + pw] = ele;\n          }\n        }\n        input_data += input_stride;\n        output_data += output_stride;\n      }\n    }\n  } };",
                                                "sequence": [
                                                      {
                                                            "class": "add",
                                                            "loc": [") {\n"],
                                                            "code": [
                                                                  "std::vector<int> tmp;\n",
                                                                  "if (typeid(dilation) == typeid(int)) { tmp.push_back(dilation); }\n",
                                                                  "else if (typeid(dilation) == typeid(std::vector<int>)) { tmp = dilation; }\n",
                                                                  "const int dilationH = tmp[0];\n",
                                                                  "const int dilationW = tmp.size() == 1 ? dilationT : tmp[1];\n"
                                                            ]
                                                      },
                                                      {
                                                            "class": "modify",
                                                            "loc": ["hend = std::min(hstart + ksize_height,\n                              input_height + padding_height);"],
                                                            "code": [
                                                                  {
                                                                        "ksize_height": "ksize_height * dilationH"
                                                                  }
                                                            ]
                                                      },
                                                      {
                                                            "class": "modify",
                                                            "loc": ["wend =\n                    std::min(wstart + ksize_width, input_width + padding_width);"],
                                                            "code": [
                                                                  {
                                                                        "ksize_width": "ksize_width * dilationW"
                                                                  }
                                                            ]
                                                      },
                                                      {
                                                            "class": "modify",
                                                            "loc": ["pool_size = (hend - hstart) * (wend - wstart);"],
                                                            "code": [
                                                                  {
                                                                        "(hend - hstart)": "(hend - hstart) / dilationH",
                                                                        "(wend - wstart)": "(wend - wstart) / dilationW"
                                                                  }
                                                            ]
                                                      },
                                                      {
                                                            "class": "modify",
                                                            "loc": ["for (int h = hstart; h < hend; ++h)"],
                                                            "code": [
                                                                  {
                                                                        "++h": "h += dilationH"
                                                                  }
                                                            ]
                                                      },
                                                      {
                                                            "class": "modify",
                                                            "loc": ["for (int w = wstart; w < wend; ++w)"],
                                                            "code": [
                                                                  {
                                                                        "++w":"w += dilationW"
                                                                  }
                                                            ]
                                                      }
                                                ]
                                          },
                                          "GPU": {
                                                "header": [
                                                      "#include <algorithm>",
                                                      "#include <vector>",
                                                      "#include \"paddle/phi/backends/gpu/gpu_launch_config.h\"",
                                                      "#include \"paddle/phi/backends/gpu/gpu_primitives.h\"",
                                                      "#include \"paddle/phi/kernels/funcs/pooling.h\"",
                                                      "#include \"paddle/phi/kernels/funcs/reduce_function.h\"",
                                                      "#include \"paddle/phi/kernels/primitive/datamover_primitives.h\""
                                                ],
                                                "funcContext": [],
                                                "sourceCode": "template <typename PoolProcess, typename T>\n__global__ void KernelPool2D(const int nthreads,\n                             const T* input_data,\n                             const int channels,\n                             const int input_height,\n                             const int input_width,\n                             const int output_height,\n                             const int output_width,\n                             const int ksize_height,\n                             const int ksize_width,\n                             const int stride_height,\n                             const int stride_width,\n                             const int padding_height,\n                             const int padding_width,\n                             FastDivModForPooling divmods,\n                             PoolProcess pool_process,\n                             bool exclusive,\n                             T* output_data,\n                             bool channel_last = false) {\n  for (int index = blockIdx.x * blockDim.x + threadIdx.x; index < nthreads;\n       index += blockDim.x * gridDim.x) {\n    int hstart, hend, wstart, wend;\n    int w_offset, h_offset, c_offset, input_offset;\n    OffsetPreparationFor4Dimension<FastDivModForPooling>(index,\n                                                         channel_last,\n                                                         divmods,\n                                                         0,\n                                                         0,\n                                                         input_width,\n                                                         input_height,\n                                                         &w_offset,\n                                                         &h_offset,\n                                                         &c_offset,\n                                                         &input_offset);\n    input_data += input_offset;\n\n    hstart = h_offset * stride_height - padding_height;\n    hend = min(hstart + ksize_height, input_height);\n    hstart = max(hstart, 0);\n    wstart = w_offset * stride_width - padding_width;\n    wend = min(wstart + ksize_width, input_width);\n    wstart = max(wstart, 0);\n\n    T ele = pool_process.initial();\n    for (int h = hstart; h < hend; ++h) {\n      for (int w = wstart; w < wend; ++w) {\n        auto input_idx = channel_last\n                             ? (h * input_width + w) * channels + c_offset\n                             : h * input_width + w;\n        pool_process.compute(input_data[input_idx], &ele);\n      }\n    }\n    int pool_size = exclusive ? (hend - hstart) * (wend - wstart)\n                              : ksize_height * ksize_width;\n    pool_process.finalize(static_cast<T>(pool_size), &ele);\n    output_data[index] = ele;\n  }\n}",
                                                "sequence": [
                                                      {
                                                            "class": "add",
                                                            "loc": [") {\n"],
                                                            "code": [
                                                                  "std::vector<int> tmp;\n",
                                                                  "if (typeid(dilation) == typeid(int)) { tmp.push_back(dilation); }\n",
                                                                  "else if (typeid(dilation) == typeid(std::vector<int>)) { tmp = dilation; }\n",
                                                                  "const int dilationT = tmp[0];\n",
                                                                  "const int dilationH = tmp.size() == 1 ? dilationT : tmp[1];\n",
                                                                  "const int dilationW = tmp.size() == 1 ? dilationT : tmp[2];\n"
                                                            ]
                                                      },
                                                      {
                                                            "class": "modify",
                                                            "loc": ["hend = min(hstart + ksize_height, input_height);"],
                                                            "code": [
                                                                  {
                                                                        "ksize_height": "ksize_height * dilationH"
                                                                  }
                                                            ]
                                                      },
                                                      {
                                                            "class": "modify",
                                                            "loc": ["wend = min(wstart + ksize_width, input_width);"],
                                                            "code": [
                                                                  {
                                                                        "ksize_width": "ksize_width * dilationW"
                                                                  }
                                                            ]
                                                      },
                                                      {
                                                            "class": "modify",
                                                            "loc": ["for (int h = hstart; h < hend; ++h)"],
                                                            "code": [
                                                                  {
                                                                        "++h": "h += dilationH"
                                                                  }
                                                            ]
                                                      },
                                                      {
                                                            "class": "modify",
                                                            "loc": ["for (int w = wstart; w < wend; ++w)"],
                                                            "code": [
                                                                  {
                                                                        "++w":"w += dilationW"
                                                                  }
                                                            ]
                                                      },
                                                      {
                                                            "class": "modify",
                                                            "loc": ["int pool_size = exclusive ? (hend - hstart) * (wend - wstart)\n                              : ksize_height * ksize_width;"],
                                                            "code": [
                                                                  {
                                                                        "(hend - hstart)": "(hend - hstart) / dilationH",
                                                                        "(wend - wstart)": "(wend - wstart) / dilationW"
                                                                  }
                                                            ]
                                                      }
                                                ]
                                          }
                                    }
                              }
                        ]
                  }
            ]
      },
      "torch.nn.MaxPool2d": {
            "Matcher": "FuncParamMatcher",
            "Classification": 1,
            "params_change": {
                  "return_indices": "return_mask"
            },
            "variantCode": [
                  {
                        "param": "dilation",
                        "operatorSequence": [
                              {
                                    "level": "C underlying library",
                                    "function": {
                                          "CPU": "Pool2dFunctor",
                                          "GPU": "Pool2dFunctor"
                                    },
                                    "namespace": {
                                          "CPU": [
                                                "phi",
                                                "funcs"
                                          ],
                                          "GPU": [
                                                "phi",
                                                "funcs"
                                          ]
                                    },
                                    "backend": {
                                          "CPU":{
                                               "headers": [
                                                     "#include \"paddle/phi/kernels/funcs/pooling.h\"",
                                                     "#include <algorithm>",
                                                     "#include <vector>",
                                                     "#include \"paddle/phi/backends/cpu/cpu_context.h\""
                                               ],
                                                "funcContext": [],
                                                "sourceCode": "template <typename PoolProcess, typename T>\nclass Pool2dFunctor<CPUContext, PoolProcess, T> {\n public:\n  void operator()(const CPUContext& context,\n                  const DenseTensor& input,\n                  const std::vector<int>& ksize,\n                  const std::vector<int>& strides,\n                  const std::vector<int>& paddings,\n                  bool exclusive,\n                  bool adaptive,\n                  DenseTensor* output,\n                  PoolProcess pool_process) {\n    const int batch_size = input.dims()[0];\n    const int input_height = input.dims()[2];\n    const int input_width = input.dims()[3];\n    const int output_channels = output->dims()[1];\n    const int output_height = output->dims()[2];\n    const int output_width = output->dims()[3];\n    const int ksize_height = ksize[0];\n    const int ksize_width = ksize[1];\n    const int stride_height = strides[0];\n    const int stride_width = strides[1];\n    const int padding_height = paddings[0];\n    const int padding_width = paddings[1];\n\n    const int input_stride = input_height * input_width;\n    const int output_stride = output_height * output_width;\n\n    const T* input_data = input.data<T>();\n    T* output_data = context.template Alloc<T>(output);\n\n    int hstart = 0, hend = 1;\n    int wstart = 0, wend = 1;\n    for (int i = 0; i < batch_size; i++) {\n      for (int c = 0; c < output_channels; ++c) {\n        for (int ph = 0; ph < output_height; ++ph) {\n          if (adaptive) {\n            hstart = AdaptStartIndex(ph, input_height, output_height);\n            hend = AdaptEndIndex(ph, input_height, output_height);\n          }\n          for (int pw = 0; pw < output_width; ++pw) {\n            int pool_size = 1;\n            if (adaptive) {\n              wstart = AdaptStartIndex(pw, input_width, output_width);\n              wend = AdaptEndIndex(pw, input_width, output_width);\n            } else {\n              hstart = ph * stride_height - padding_height;\n              wstart = pw * stride_width - padding_width;\n              hend = std::min(hstart + ksize_height,\n                              input_height + padding_height);\n              wend =\n                  std::min(wstart + ksize_width, input_width + padding_width);\n              pool_size = (hend - hstart) * (wend - wstart);\n\n              wstart = std::max(wstart, 0);\n              hstart = std::max(hstart, 0);\n              hend = std::min(hend, input_height);\n              wend = std::min(wend, input_width);\n            }\n\n            T ele = pool_process.initial();\n            for (int h = hstart; h < hend; ++h) {\n              for (int w = wstart; w < wend; ++w) {\n                pool_process.compute(input_data[h * input_width + w], &ele);\n              }\n            }\n            if (exclusive || adaptive) {\n              pool_size = (hend - hstart) * (wend - wstart);\n            }\n\n            pool_process.finalize(static_cast<T>(pool_size), &ele);\n            output_data[ph * output_width + pw] = ele;\n          }\n        }\n        input_data += input_stride;\n        output_data += output_stride;\n      }\n    }\n  } };",
                                                "sequence": [
                                                      {
                                                            "class": "add",
                                                            "loc": ["int hstart = 0, hend = 1;\n    int wstart = 0, wend = 1;"],
                                                            "code": [
                                                                  "std::vector<int> tmp;\n",
                                                                  "if (typeid(dilation) == typeid(int)) { tmp.push_back(dilation); }\n",
                                                                  "else if (typeid(dilation) == typeid(std::vector<int>)) { tmp = dilation; }\n",
                                                                  "const int dilationT = tmp[0];\n",
                                                                  "const int dilationH = tmp.size() == 1 ? dilationT : tmp[1];\n",
                                                                  "const int dilationW = tmp.size() == 1 ? dilationT : tmp[2];\n"
                                                            ]
                                                      },
                                                      {
                                                            "class": "modify",
                                                            "loc": ["dend =\n                    std::min(dstart + ksize_depth, input_depth + padding_depth);"],
                                                            "code": [
                                                                  {
                                                                      "ksize_depth": "ksize_depth * dilationT"
                                                                  }
                                                            ]
                                                      },
                                                      {
                                                            "class": "modify",
                                                            "loc": ["hend = std::min(hstart + ksize_height,\n                                input_height + padding_height);"],
                                                            "code": [
                                                                  {
                                                                        "ksize_height": "ksize_height * dilationH"
                                                                  }
                                                            ]
                                                      },
                                                      {
                                                            "class": "modify",
                                                            "loc": ["wend =\n                    std::min(wstart + ksize_width, input_width + padding_width);"],
                                                            "code": [
                                                                  {
                                                                        "ksize_width": "ksize_width * dilationW"
                                                                  }
                                                            ]
                                                      },
                                                      {
                                                            "class": "modify",
                                                            "loc": ["pool_size = (dend - dstart) * (hend - hstart) * (wend - wstart);"],
                                                            "code": [
                                                                  {
                                                                        "(dend - dstart)": "(dend - dstart) / dilationT",
                                                                        "(hend - hstart)": "(hend - hstart) / dilationH",
                                                                        "(wend - wstart)": "(wend - wstart) / dilationW"
                                                                  }
                                                            ]
                                                      },
                                                      {
                                                            "class": "modify",
                                                            "loc": ["for (int d = dstart; d < dend; ++d)"],
                                                            "code": [
                                                                  {
                                                                        "++d": "d += dilationT"
                                                                  }
                                                            ]
                                                      },
                                                      {
                                                            "class": "modify",
                                                            "loc": ["for (int h = hstart; h < hend; ++h)"],
                                                            "code": [
                                                                  {
                                                                        "++h": "h += dilationH"
                                                                  }
                                                            ]
                                                      },
                                                      {
                                                            "class": "modify",
                                                            "loc": ["for (int w = wstart; w < wend; ++w)"],
                                                            "code": [
                                                                  {
                                                                        "++w":"w += dilationW"
                                                                  }
                                                            ]
                                                      }
                                                ]
                                          },
                                          "GPU": {
                                                "headers": [
                                                      "#include <algorithm>",
                                                      "#include <vector>",
                                                      "#include \"paddle/phi/backends/gpu/gpu_launch_config.h\"",
                                                      "#include \"paddle/phi/backends/gpu/gpu_primitives.h\"",
                                                      "#include \"paddle/phi/kernels/funcs/pooling.h\"",
                                                      "#include \"paddle/phi/kernels/funcs/reduce_function.h\"",
                                                      "#include \"paddle/phi/kernels/primitive/datamover_primitives.h\""
                                                ],
                                                "funcContext": [
                                                       "struct FastDivModForPooling {\n public:\n  phi::kps::details::FastDivMod channel;\n  phi::kps::details::FastDivMod width;\n  phi::kps::details::FastDivMod height;\n\n  explicit HOSTDEVICE FastDivModForPooling(const int channels,\n                                           const int output_width,\n                                           const int output_height) {\n    channel = phi::kps::details::FastDivMod(channels);\n    width = phi::kps::details::FastDivMod(output_width);\n    height = phi::kps::details::FastDivMod(output_height);\n  }\n};",
                                                       "template <typename FastDivModForPooling>\n__device__ void OffsetPreparationFor4Dimension(int index,\n                                               bool channel_last,\n                                               FastDivModForPooling divmods,\n                                               const int pad_width,\n                                               const int pad_height,\n                                               const int aux_width,\n                                               const int aux_height,\n                                               int* w_offset,\n                                               int* h_offset,\n                                               int* c_offset,\n                                               int* stride) {\n  if (!channel_last) { /* NCHW */\n    auto input_width_divmod = divmods.width.Divmod(index);\n    auto input_height_divmod = divmods.height.Divmod(input_width_divmod.val[0]);\n    auto channel_divmod = divmods.channel.Divmod(input_height_divmod.val[0]);\n    *w_offset = input_width_divmod.val[1] + pad_width;\n    *h_offset = input_height_divmod.val[1] + pad_height;\n    *c_offset = channel_divmod.val[1];\n    *stride = (channel_divmod.val[0] * divmods.channel.divisor + *c_offset) *\n              aux_height * aux_width;\n  } else { /* NHWC */\n    auto c_divmod = divmods.channel.Divmod(index);\n    auto input_width_divmod = divmods.width.Divmod(c_divmod.val[0]);\n    auto input_height_divmod = divmods.height.Divmod(input_width_divmod.val[0]);\n    *c_offset = c_divmod.val[1];\n    *w_offset = input_width_divmod.val[1] + pad_width;\n    *h_offset = input_height_divmod.val[1] + pad_height;\n    *stride = input_height_divmod.val[0] * aux_height * aux_width *\n              divmods.channel.divisor;\n  }\n}\n"
                                                ],
                                                "sourceCode": "template <typename PoolProcess, typename T>\n__global__ void KernelPool2D(const int nthreads,\n                             const T* input_data,\n                             const int channels,\n                             const int input_height,\n                             const int input_width,\n                             const int output_height,\n                             const int output_width,\n                             const int ksize_height,\n                             const int ksize_width,\n                             const int stride_height,\n                             const int stride_width,\n                             const int padding_height,\n                             const int padding_width,\n                             FastDivModForPooling divmods,\n                             PoolProcess pool_process,\n                             bool exclusive,\n                             T* output_data,\n                             bool channel_last = false) {\n  for (int index = blockIdx.x * blockDim.x + threadIdx.x; index < nthreads;\n       index += blockDim.x * gridDim.x) {\n    int hstart, hend, wstart, wend;\n    int w_offset, h_offset, c_offset, input_offset;\n    OffsetPreparationFor4Dimension<FastDivModForPooling>(index,\n                                                         channel_last,\n                                                         divmods,\n                                                         0,\n                                                         0,\n                                                         input_width,\n                                                         input_height,\n                                                         &w_offset,\n                                                         &h_offset,\n                                                         &c_offset,\n                                                         &input_offset);\n    input_data += input_offset;\n\n    hstart = h_offset * stride_height - padding_height;\n    hend = min(hstart + ksize_height, input_height);\n    hstart = max(hstart, 0);\n    wstart = w_offset * stride_width - padding_width;\n    wend = min(wstart + ksize_width, input_width);\n    wstart = max(wstart, 0);\n\n    T ele = pool_process.initial();\n    for (int h = hstart; h < hend; ++h) {\n      for (int w = wstart; w < wend; ++w) {\n        auto input_idx = channel_last\n                             ? (h * input_width + w) * channels + c_offset\n                             : h * input_width + w;\n        pool_process.compute(input_data[input_idx], &ele);\n      }\n    }\n    int pool_size = exclusive ? (hend - hstart) * (wend - wstart)\n                              : ksize_height * ksize_width;\n    pool_process.finalize(static_cast<T>(pool_size), &ele);\n    output_data[index] = ele;\n  }\n}\n",
                                                "sequence": [
                                                     {
                                                            "class": "add",
                                                            "loc": [") {\n"],
                                                            "code": [
                                                                  "std::vector<int> tmp;\n",
                                                                  "if (typeid(dilation) == typeid(int)) { tmp.push_back(dilation); }\n",
                                                                  "else if (typeid(dilation) == typeid(std::vector<int>)) { tmp = dilation; }\n",
                                                                  "const int dilationT = tmp[0];\n",
                                                                  "const int dilationH = tmp.size() == 1 ? dilationT : tmp[1];\n",
                                                                  "const int dilationW = tmp.size() == 1 ? dilationT : tmp[2];\n"
                                                            ]
                                                     },
                                                     {
                                                            "class": "modify",
                                                            "loc": ["dend = min(dstart + ksize_depth, input_depth);"],
                                                            "code": [
                                                                  {
                                                                      "ksize_depth": "ksize_depth * dilationT"
                                                                  }
                                                            ]
                                                      },
                                                      {
                                                            "class": "modify",
                                                            "loc": ["hend = min(hstart + ksize_height, input_height);"],
                                                            "code": [
                                                                  {
                                                                        "ksize_height": "ksize_height * dilationH"
                                                                  }
                                                            ]
                                                      },
                                                      {
                                                            "class": "modify",
                                                            "loc": ["wend = min(wstart + ksize_width, input_width);"],
                                                            "code": [
                                                                  {
                                                                        "ksize_width": "ksize_width * dilationW"
                                                                  }
                                                            ]
                                                      },
                                                      {
                                                            "class": "modify",
                                                            "loc": ["int pool_size = (exclusive || adaptive)\n                        ? (dend - dstart) * (hend - hstart) * (wend - wstart)\n                        : ksize_depth * ksize_height * ksize_width;"],
                                                            "code": [
                                                                  {
                                                                        "(dend - dstart)": "(dend - dstart) / dilationT",
                                                                        "(hend - hstart)": "(hend - hstart) / dilationH",
                                                                        "(wend - wstart)": "(wend - wstart) / dilationW"
                                                                  }
                                                            ]
                                                      },
                                                      {
                                                            "class": "modify",
                                                            "loc": ["for (int d = dstart; d < dend; ++d)"],
                                                            "code": [
                                                                  {
                                                                        "++d": "d += dilationT"
                                                                  }
                                                            ]
                                                      },
                                                      {
                                                            "class": "modify",
                                                            "loc": ["for (int h = hstart; h < hend; ++h)"],
                                                            "code": [
                                                                  {
                                                                        "++h": "h += dilationH"
                                                                  }
                                                            ]
                                                      },
                                                      {
                                                            "class": "modify",
                                                            "loc": ["for (int w = wstart; w < wend; ++w)"],
                                                            "code": [
                                                                  {
                                                                        "++w":"w += dilationW"
                                                                  }
                                                            ]
                                                      }
                                                ]
                                          }
                                    }
                              }
                        ]
                  }
            ]
      },
      "torch.nn.MaxPool3d": {
            "Matcher": "FuncParamMatcher",
            "Classification": 1,
            "params_change": {
                  "return_indices": "return_mask"
            },
            "variantCode": [
                  {
                        "param": "dilation",
                        "operatorSequence": [
                              {
                                    "level": "C underlying library",
                                    "function": {
                                          "CPU": "Pool3dFunctor",
                                          "GPU": "Pool3dFunctor"
                                    },
                                    "namespace": {
                                          "CPU": [
                                                "phi",
                                                "funcs"
                                          ],
                                          "GPU": [
                                                "phi",
                                                "funcs"
                                          ]
                                    },
                                    "backend": {
                                          "CPU":{
                                               "headers": [
                                                     "#include \"paddle/phi/kernels/funcs/pooling.h\"",
                                                     "#include <algorithm>",
                                                     "#include <vector>",
                                                     "#include \"paddle/phi/backends/cpu/cpu_context.h\""
                                               ],
                                                "funcContext": [],
                                                "sourceCode": "class Pool3dFunctor<CPUContext, PoolProcess, T> {\n public:\n  void operator()(const CPUContext& context,\n                  const DenseTensor& input,\n                  const std::vector<int>& ksize,\n                  const std::vector<int>& strides,\n                  const std::vector<int>& paddings,\n                  bool exclusive,\n                  bool adaptive,\n                  DenseTensor* output,\n                  PoolProcess pool_process) {\n    const int batch_size = input.dims()[0];\n    const int input_depth = input.dims()[2];\n    const int input_height = input.dims()[3];\n    const int input_width = input.dims()[4];\n    const int output_channels = output->dims()[1];\n    const int output_depth = output->dims()[2];\n    const int output_height = output->dims()[3];\n    const int output_width = output->dims()[4];\n    const int ksize_depth = ksize[0];\n    const int ksize_height = ksize[1];\n    const int ksize_width = ksize[2];\n    const int stride_depth = strides[0];\n    const int stride_height = strides[1];\n    const int stride_width = strides[2];\n    const int padding_depth = paddings[0];\n    const int padding_height = paddings[1];\n    const int padding_width = paddings[2];\n\n    const int input_stride = input_depth * input_height * input_width;\n    const int output_stride = output_depth * output_height * output_width;\n\n    const T* input_data = input.data<T>();\n    T* output_data = context.template Alloc<T>(output);\n\n    int dstart = 0, dend = 1;\n    int hstart = 0, hend = 1;\n    int wstart = 0, wend = 1;\n\n    for (int i = 0; i < batch_size; i++) {\n      for (int c = 0; c < output_channels; ++c) {\n        for (int pd = 0; pd < output_depth; ++pd) {\n          if (adaptive) {\n            dstart = AdaptStartIndex(pd, input_depth, output_depth);\n            dend = AdaptEndIndex(pd, input_depth, output_depth);\n          }\n\n          for (int ph = 0; ph < output_height; ++ph) {\n            if (adaptive) {\n              hstart = AdaptStartIndex(ph, input_height, output_height);\n              hend = AdaptEndIndex(ph, input_height, output_height);\n            }\n\n            for (int pw = 0; pw < output_width; ++pw) {\n              int pool_size = 1;\n              if (adaptive) {\n                wstart = AdaptStartIndex(pw, input_width, output_width);\n                wend = AdaptEndIndex(pw, input_width, output_width);\n              } else {\n                dstart = pd * stride_depth - padding_depth;\n                dend =\n                    std::min(dstart + ksize_depth, input_depth + padding_depth);\n                hstart = ph * stride_height - padding_height;\n                hend = std::min(hstart + ksize_height,\n                                input_height + padding_height);\n                wstart = pw * stride_width - padding_width;\n                wend =\n                    std::min(wstart + ksize_width, input_width + padding_width);\n                pool_size = (dend - dstart) * (hend - hstart) * (wend - wstart);\n                dstart = std::max(dstart, 0);\n                hstart = std::max(hstart, 0);\n                wstart = std::max(wstart, 0);\n                dend = std::min(dend, input_depth);\n                hend = std::min(hend, input_height);\n                wend = std::min(wend, input_width);\n              }\n              int output_idx = (pd * output_height + ph) * output_width + pw;\n              T ele = pool_process.initial();\n              for (int d = dstart; d < dend; ++d) {\n                for (int h = hstart; h < hend; ++h) {\n                  for (int w = wstart; w < wend; ++w) {\n                    pool_process.compute(\n                        input_data[(d * input_height + h) * input_width + w],\n                        &ele);\n                  }\n                }\n              }\n              if (exclusive || adaptive) {\n                pool_size = (dend - dstart) * (hend - hstart) * (wend - wstart);\n              }\n              pool_process.finalize(static_cast<T>(pool_size), &ele);\n              output_data[output_idx] = ele;\n            }\n          }\n        }\n        input_data += input_stride;\n        output_data += output_stride;\n      }\n    }\n  } };",
                                                "sequence": [
                                                      {
                                                            "class": "add",
                                                            "loc": [") {\n"],
                                                            "code": [
                                                                  "std::vector<int> tmp;\n",
                                                                  "if (typeid(dilation) == typeid(int)) { tmp.push_back(dilation); }\n",
                                                                  "else if (typeid(dilation) == typeid(std::vector<int>)) { tmp = dilation; }\n",
                                                                  "const int dilationT = tmp[0];\n",
                                                                  "const int dilationH = tmp.size() == 1 ? dilationT : tmp[1];\n",
                                                                  "const int dilationW = tmp.size() == 1 ? dilationT : tmp[2];\n"
                                                            ]
                                                      },
                                                      {
                                                            "class": "modify",
                                                            "loc": ["dend =\n                    std::min(dstart + ksize_depth, input_depth + padding_depth);"],
                                                            "code": [
                                                                  {
                                                                      "ksize_depth": "ksize_depth * dilationT"
                                                                  }
                                                            ]
                                                      },
                                                      {
                                                            "class": "modify",
                                                            "loc": ["hend = std::min(hstart + ksize_height,\n                                input_height + padding_height);"],
                                                            "code": [
                                                                  {
                                                                        "ksize_height": "ksize_height * dilationH"
                                                                  }
                                                            ]
                                                      },
                                                      {
                                                            "class": "modify",
                                                            "loc": ["wend =\n                    std::min(wstart + ksize_width, input_width + padding_width);"],
                                                            "code": [
                                                                  {
                                                                        "ksize_width": "ksize_width * dilationW"
                                                                  }
                                                            ]
                                                      },
                                                      {
                                                            "class": "modify",
                                                            "loc": ["pool_size = (dend - dstart) * (hend - hstart) * (wend - wstart);"],
                                                            "code": [
                                                                  {
                                                                        "(dend - dstart)": "(dend - dstart) / dilationT",
                                                                        "(hend - hstart)": "(hend - hstart) / dilationH",
                                                                        "(wend - wstart)": "(wend - wstart) / dilationW"
                                                                  }
                                                            ]
                                                      },
                                                      {
                                                            "class": "modify",
                                                            "loc": ["for (int d = dstart; d < dend; ++d)"],
                                                            "code": [
                                                                  {
                                                                        "++d": "d += dilationT"
                                                                  }
                                                            ]
                                                      },
                                                      {
                                                            "class": "modify",
                                                            "loc": ["for (int h = hstart; h < hend; ++h)"],
                                                            "code": [
                                                                  {
                                                                        "++h": "h += dilationH"
                                                                  }
                                                            ]
                                                      },
                                                      {
                                                            "class": "modify",
                                                            "loc": ["for (int w = wstart; w < wend; ++w)"],
                                                            "code": [
                                                                  {
                                                                        "++w":"w += dilationW"
                                                                  }
                                                            ]
                                                      }
                                                ]
                                          },
                                          "GPU": {
                                                "headers": [
                                                      "#include <algorithm>",
                                                      "#include <vector>",
                                                      "#include \"paddle/phi/backends/gpu/gpu_launch_config.h\"",
                                                      "#include \"paddle/phi/backends/gpu/gpu_primitives.h\"",
                                                      "#include \"paddle/phi/kernels/funcs/pooling.h\"",
                                                      "#include \"paddle/phi/kernels/funcs/reduce_function.h\"",
                                                      "#include \"paddle/phi/kernels/primitive/datamover_primitives.h\""
                                                ],
                                                "funcContext": [],
                                                "sourceCode": "template <typename PoolProcess, typename T>\n__global__ void KernelPool3D(const int nthreads,\n                             const T* input_data,\n                             const int channels,\n                             const int input_depth,\n                             const int input_height,\n                             const int input_width,\n                             const int output_depth,\n                             const int output_height,\n                             const int output_width,\n                             const int ksize_depth,\n                             const int ksize_height,\n                             const int ksize_width,\n                             const int stride_depth,\n                             const int stride_height,\n                             const int stride_width,\n                             const int padding_depth,\n                             const int padding_height,\n                             const int padding_width,\n                             PoolProcess pool_process,\n                             bool exclusive,\n                             bool adaptive,\n                             T* output_data,\n                             bool channel_last = false) {\n  for (int index = blockIdx.x * blockDim.x + threadIdx.x; index < nthreads;\n       index += blockDim.x * gridDim.x) {\n    int pw, ph, pd, c, batch_idx;\n    if (!channel_last) {\n      pw = index % output_width;\n      ph = (index / output_width) % output_height;\n      pd = (index / output_width / output_height) % output_depth;\n      c = (index / output_width / output_height / output_depth) % channels;\n      batch_idx =\n          index / output_width / output_height / output_depth / channels;\n    } else {\n      c = index % channels;\n      pw = (index / channels) % output_width;\n      ph = (index / channels / output_width) % output_height;\n      pd = (index / channels / output_width / output_height) % output_depth;\n      batch_idx =\n          index / channels / output_width / output_height / output_depth;\n    }\n\n    int dstart, dend;\n    int hstart, hend;\n    int wstart, wend;\n    if (adaptive) {\n      dstart = AdaptStartIndex(pd, input_depth, output_depth);\n      dend = AdaptEndIndex(pd, input_depth, output_depth);\n\n      hstart = AdaptStartIndex(ph, input_height, output_height);\n      hend = AdaptEndIndex(ph, input_height, output_height);\n\n      wstart = AdaptStartIndex(pw, input_width, output_width);\n      wend = AdaptEndIndex(pw, input_width, output_width);\n    } else {\n      dstart = pd * stride_depth - padding_depth;\n      hstart = ph * stride_height - padding_height;\n      wstart = pw * stride_width - padding_width;\n      dend = min(dstart + ksize_depth, input_depth);\n      hend = min(hstart + ksize_height, input_height);\n      wend = min(wstart + ksize_width, input_width);\n      dstart = max(dstart, 0);\n      hstart = max(hstart, 0);\n      wstart = max(wstart, 0);\n    }\n\n    int input_data_stride;\n    if (!channel_last) { /* NCDHW */\n      input_data_stride =\n          (batch_idx * channels + c) * input_depth * input_height * input_width;\n    } else { /* NDHWC */\n      input_data_stride =\n          batch_idx * input_depth * input_height * input_width * channels;\n    }\n    input_data += input_data_stride;\n\n    T ele = pool_process.initial();\n    for (int d = dstart; d < dend; ++d) {\n      for (int h = hstart; h < hend; ++h) {\n        for (int w = wstart; w < wend; ++w) {\n          auto input_data_idx =\n              channel_last\n                  ? ((d * input_height + h) * input_width + w) * channels + c\n                  : (d * input_height + h) * input_width + w;\n          pool_process.compute(input_data[input_data_idx], &ele);\n        }\n      }\n    }\n    int pool_size = (exclusive || adaptive)\n                        ? (dend - dstart) * (hend - hstart) * (wend - wstart)\n                        : ksize_depth * ksize_height * ksize_width;\n    pool_process.finalize(static_cast<T>(pool_size), &ele);\n    output_data[index] = ele;\n  }\n}",
                                                "sequence": [
                                                      {
                                                            "class": "add",
                                                            "loc": [") {\n"],
                                                            "code": [
                                                                  "std::vector<int> tmp;\n",
                                                                  "if (typeid(dilation) == typeid(int)) { tmp.push_back(dilation); }\n",
                                                                  "else if (typeid(dilation) == typeid(std::vector<int>)) { tmp = dilation; }\n",
                                                                  "const int dilationT = tmp[0];\n",
                                                                  "const int dilationH = tmp.size() == 1 ? dilationT : tmp[1];\n",
                                                                  "const int dilationW = tmp.size() == 1 ? dilationT : tmp[2];\n"
                                                            ]
                                                      },
                                                      {
                                                            "class": "modify",
                                                            "loc": ["dend = min(dstart + ksize_depth, input_depth);"],
                                                            "code": [
                                                                  {
                                                                      "ksize_depth": "ksize_depth * dilationT"
                                                                  }
                                                            ]
                                                      },
                                                      {
                                                            "class": "modify",
                                                            "loc": ["hend = min(hstart + ksize_height, input_height);"],
                                                            "code": [
                                                                  {
                                                                        "ksize_height": "ksize_height * dilationH"
                                                                  }
                                                            ]
                                                      },
                                                      {
                                                            "class": "modify",
                                                            "loc": ["wend = min(wstart + ksize_width, input_width);"],
                                                            "code": [
                                                                  {
                                                                        "ksize_width": "ksize_width * dilationW"
                                                                  }
                                                            ]
                                                      },
                                                      {
                                                            "class": "modify",
                                                            "loc": ["int pool_size = (exclusive || adaptive)\n                        ? (dend - dstart) * (hend - hstart) * (wend - wstart)\n                        : ksize_depth * ksize_height * ksize_width;"],
                                                            "code": [
                                                                  {
                                                                        "(dend - dstart)": "(dend - dstart) / dilationT",
                                                                        "(hend - hstart)": "(hend - hstart) / dilationH",
                                                                        "(wend - wstart)": "(wend - wstart) / dilationW"
                                                                  }
                                                            ]
                                                      },
                                                      {
                                                            "class": "modify",
                                                            "loc": ["for (int d = dstart; d < dend; ++d)"],
                                                            "code": [
                                                                  {
                                                                        "++d": "d += dilationT"
                                                                  }
                                                            ]
                                                      },
                                                      {
                                                            "class": "modify",
                                                            "loc": ["for (int h = hstart; h < hend; ++h)"],
                                                            "code": [
                                                                  {
                                                                        "++h": "h += dilationH"
                                                                  }
                                                            ]
                                                      },
                                                      {
                                                            "class": "modify",
                                                            "loc": ["for (int w = wstart; w < wend; ++w)"],
                                                            "code": [
                                                                  {
                                                                        "++w":"w += dilationW"
                                                                  }
                                                            ]
                                                      }
                                                ]
                                          }
                                    }
                              }
                        ]
                  }
            ]
      },
      "torch.nn.MaxUnpool1d": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.nn.MaxUnpool2d": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.nn.MaxUnpool3d": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.nn.AvgPool1d": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "params_change": {
                  "count_include_pad": "exclusive"
            }
      },
      "torch.nn.AvgPool2d": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "params_change": {
                  "count_include_pad": "exclusive"
            }
      },
      "torch.nn.AvgPool3d": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "params_change": {
                  "count_include_pad": "exclusive"
            }
      },
      "torch.nn.AdaptiveMaxPool1d": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "params_change": {
                  "return_indices": "return_mask"
            }
      },
      "torch.nn.AdaptiveMaxPool2d": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "params_change": {
                  "return_indices": "return_mask"
            }
      },
      "torch.nn.AdaptiveMaxPool3d": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "params_change": {
                  "return_indices": "return_mask"
            }
      },
      "torch.nn.LPPool1d": {
            "Matcher": "OCSMatcher",
            "Classification": 2,
            "operatorSequence": [
                {
                        "function": "lp_pool1d",
                        "params": [
                              "input",
                              "norm_type",
                              "kernel_size",
                              "stride",
                              "ceil_mode"
                        ],
                        "ReturnSequence": {
                              "return": "(torch.sign(out) * relu(torch.abs(out))).mul(kernel_size).pow(1.0 / norm_type)",
                              "out": {
                                    "condition":  "stride is not None",
                                    "true_branch": "avg_pool2d(input.pow(norm_type), kernel_size, stride, 0, ceil_mode)",
                                    "flase_branch": "avg_pool2d(input.pow(norm_type), kernel_size, padding=0, ceil_mode=ceil_mode)"
                              }
                        }
                }
            ]
      },
      "torch.nn.LPPool2d": {
            "Matcher": "OCSMatcher",
            "Classification": 2,
            "operatorSequence": [
                {
                        "function": "lp_pool2d",
                        "params": [
                              "input",
                              "norm_type",
                              "kernel_size",
                              "stride",
                              "ceil_mode"
                        ],
                        "ReturnSequence": {
                              "return": "(torch.sign(out) * relu(torch.abs(out))).mul(kw * kh).pow(1.0 / norm_type)",
                              "out": {
                                    "condition":  "stride is not None",
                                    "true_branch": "avg_pool2d(input.pow(norm_type), kernel_size, stride, 0, ceil_mode)",
                                    "flase_branch": "avg_pool2d(input.pow(norm_type), kernel_size, padding=0, ceil_mode=ceil_mode)"
                              },
                              "kw": "kernel_size[0]",
                              "kh": "kernel_size[1]"
                        }
                }
            ]
      },
      "torch.nn.AdaptiveAvgPool1d": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.nn.AdaptiveAvgPool2d": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.nn.AdaptiveAvgPool3d": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.nn.TransformerDecoder": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.nn.Transformer": {
            "Matcher": "FuncParamMatcher",
            "Classification": 0,
            "params_change": {
                  "norm_first": "normalize_before"
            },
            "variantCode": [
                  {
                        "param": "layer_norm_eps",
                        "operatorSequence": [
                              {
                                    "level": "python underlying library",
                                    "function": "__init__",
                                    "sequence": [
                                          {
                                                "class": "add",
                                                "loc": ["LayerNorm(d_model)"],
                                                "code": [
                                                      {
                                                            "LayerNorm(d_model)": "LayerNorm(d_model, epsilon=layer_norm_eps)"
                                                      }
                                                ]
                                          }
                                    ]
                              }
                        ]
                  }
            ]
      },
      "torch.nn.ChannelShuffle": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.nn.PixelShuffle": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.nn.PixelUnshuffle": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.nn.Upsample": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.nn.UpsamplingBilinear2d": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.nn.UpsamplingNearest2d": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.nn.Embedding": {
            "Matcher": "FuncParamMatcher",
            "Classification": 1,
            "params_change": {
                  "norm_first": "normalize_before",
                  "_weight": "weight_attr"
            },
            "params_deprecation": [
                  "scale_grad_by_freq"
            ],
            "params_unsupport": [
                  "max_norm",
                  "norm_type"
            ]
      },
      "torch.optim.Optimizer": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "target_api": "paddle.optimizer.Optimizer"
      },
      "torch.optim.Adadelta": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "params_change": {
                  "lr": "learning_rate",
                  "eps": "epsilon",
                  "params": "parameters"
            },
            "target_api": "paddle.optimizer.Adadelta"
      },
      "torch.optim.Adagrad": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "params_change": {
                  "lr": "learning_rate",
                  "eps": "epsilon",
                  "params": "parameters"
            },
            "target_api": "paddle.optimizer.Adagrad"
      },
      "torch.optim.AdamW": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "params_change": {
                  "lr": "learning_rate",
                  "eps": "epsilon",
                  "params": "parameters"
            },
            "params_unsupport": [
                  "amsgrad"
            ],
            "target_api": "paddle.optimizer.AdamW"
      },
      "torch.optim.Adam": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "params_change": {
                  "lr": "learning_rate",
                  "eps": "epsilon",
                  "params": "parameters",
                  "betas": [
                        "beta1",
                        "beta2"
                  ]
            },
            "params_unsupport": [
                  "amsgrad"
            ]
      },
      "torch.optim.Adamax": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "params_change": {
                  "lr": "learning_rate",
                  "eps": "epsilon",
                  "params": "parameters",
                  "betas": [
                        "beta1",
                        "beta2"
                  ]
            },
            "target_api":"paddle.optimizer.Adamax"
      },
      "torch.optim.SGD": {
            "Matcher": "FuncParamMatcher",
            "Classification": 1,
            "params_unsupport": [
                  "dampening",
                  "nesterov"
            ],
            "target_api":"paddle.optimizer.SGD"
      },
      "torch.optim.RMSprop": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "params_change": {
                  "lr": "learning_rate",
                  "alpha": "rho",
                  "params": "parameters",
                  "eps": "epsilon"
            },
            "target_api":"paddle.optimizer.RMSprop"
      },
      "torch.optim.zero_grad": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "target_api": "paddle.optimizer.Optimizer.clear_grad",
            "params_change": {
                  "set_to_none": "set_to_zero"
            }
      },
      "torch.optim.load_state_dict": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "target_api": "paddle.optimizer.Optimizer.set_state_dict"
      },
      "torch.optim.lr_scheduler.LambdaLR": {
            "Matcher": "LrschedMatcher",
            "Classification": 0,
            "target_api": "paddle.optimizer.lr.LambdaDecay"
      },
      "torch.optim.lr_scheduler.MultiplicativeLR": {
            "Matcher": "LrschedMatcher",
            "Classification": 0,
            "params_change": {
                  "total_iters": "decay_steps"
            },
            "target_api": "paddle.optimizer.lr.MultiplicativeDecay"
      },
      "torch.optim.lr_scheduler.StepLR": {
            "Matcher": "LrschedMatcher",
            "Classification": 0,
            "target_api": "paddle.optimizer.lr.StepDecay"
      },
      "torch.optim.lr_scheduler.MultiStepLR": {
            "Matcher": "LrschedMatcher",
            "Classification": 0,
            "target_api": "paddle.optimizer.lr.MultiStepDecay"
      },
      "torch.optim.lr_scheduler.ExponentialLR": {
            "Matcher": "LrschedMatcher",
            "Classification": 0,
            "target_api": "paddle.optimizer.lr.ExponentialDecay"
      },
      "torch.optim.lr_scheduler.PolynomialLR": {
            "Matcher": "LrschedMatcher",
            "Classification": 0,
            "params_change": {
                  "optimizer": "learning_rate",
                  "total_iters": "decay_steps"
            },
            "target_api": "paddle.optimizer.lr.PolynomialDecay"
      },
      "torch.optim.lr_scheduler.CosineAnnealingLR": {
            "Matcher": "LrschedMatcher",
            "Classification": 0,
            "target_api": "paddle.optimizer.lr.CosineAnnealingDecay"
      },
      "torch.optim.lr_scheduler.CyclicLR": {
            "Matcher": "LrschedMatcher",
            "Classification": 0,
            "target_api": "paddle.optimizer.lr.CyclicLR"
      },
      "torch.optim.lr_scheduler.LRScheduler": {
            "Matcher": "LrschedMatcher",
            "Classification": 0,
            "target_api": "paddle.optimizer.lr.LRScheduler"
      },
      "torch.optim.lr_scheduler.ReduceLROnPlateau": {
            "Matcher": "LrschedMatcher",
            "Classification": 0,
            "params_change": {
                  "eps": "epsilon"
            },
            "target_api": "paddle.optimizer.lr.ReduceOnPlateau"
      },
      "torch.abs": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.absolute": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "tar_api": "paddle.absolute"
      },
      "torch.angle": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.acos": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.arccos": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "tar_api": "paddle.acos"
      },
      "torch.add": {
            "Matcher": "FuncParamMatcher",
            "Classification": 1,
            "variantCode": [
                  {
                        "param": "alpha",
                        "operatorSequence": [
                              {
                                    "level": "python underlying library",
                                    "function": "add",
                                    "sequence": [
                                          {
                                                "class": "add",
                                                "loc": ["):"],
                                                "code": "y = alpha * y \n"
                                          }
                                    ]
                              }

                        ]
                  }
            ]
      },
      "torch.acosh": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.arccosh": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "tar_api": "paddle.acosh"
      },
      "torch.addmm": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.addcdiv": {
            "Matcher": "OCSMatcher",
            "Classification": 2,
            "operatorSequence": [
                  {
                        "function": "at::Tensor::addcdiv",
                        "params": [
                              "value",
                              "tensor1",
                              "tensor2"
                        ],
                        "ReturnSequence": {
                              "return": "at::_ops::addcdiv::call(const_cast<Tensor&>(*this), tensor1, tensor2, value)"
                        }
                  },
                  {
                        "function": "at::_ops::addcdiv::call",
                        "params": [
                              "self",
                              "tensor1",
                              "tensor2",
                              "value"
                        ],
                        "ReturnSequence": {
                              "return": "op.call(self, tensor1, tensor2, value)"
                        }
                  },
                  {
                        "function": "at::native::structured_addcdiv_out::impl",
                        "params": [
                              "self",
                              "tensor1",
                              "tensor2",
                              "value"
                        ],
                        "ReturnSequence": {
                              "return": "addcdiv_stub(device_type(), *this, value)"
                        }
                  },
                  {
                        "function": "addcdiv_cpu_kernel",
                        "params": [
                              "iter",
                              "value"
                        ],
                        "ReturnSequence": {
                              "return": "self_val + scalar_val * t1_val / t2_val",
                              "scalar_val": "value.to<scalar_t>()"
                        }
                  }
            ]
      },
      "torch.addcmul": {
            "Matcher": "OCSMatcher",
            "Classification": 2,
            "operatorSequence": [
                  {
                        "function": "at::Tensor::addcmul",
                        "params": [
                              "value",
                              "tensor1",
                              "tensor2"
                        ],
                        "ReturnSequence": {
                              "return": "at::_ops::addcmul::call(const_cast<Tensor&>(*this), tensor1, tensor2, value)"
                        }
                  },
                  {
                        "function": "at::_ops::addcmul::call",
                        "params": [
                              "self",
                              "tensor1",
                              "tensor2",
                              "value"
                        ],
                        "ReturnSequence": {
                              "return": "op.call(self, tensor1, tensor2, value)"
                        }
                  },
                  {
                        "function": "at::native::structured_addcmul_out::impl",
                        "params": [
                              "self",
                              "tensor1",
                              "tensor2",
                              "value"
                        ],
                        "ReturnSequence": {
                              "return": "addcmul_stub(device_type(), *this, value)"
                        }
                  },
                  {
                        "function": "addcmul_cpu_kernel",
                        "params": [
                              "iter",
                              "value"
                        ],
                        "ReturnSequence": {
                              "return": "self_val + scalar_val * t1_val * t2_val",
                              "scalar_val": "value.to<scalar_t>()"
                        }
                  }
            ]
      },
      "torch.all": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "params_change": {
                  "dim": "axis"
            }
      },
      "torch.allclose": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.isclose": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.amax": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "params_change": {
                  "dim": "axis"
            }
      },
      "torch.amin": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "params_change": {
                  "dim": "axis"
            }
      },
      "torch.any": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "params_change": {
                  "dim": "axis"
            }
      },
      "torch.asin": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.arcsin": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "target_api": "paddle.asin"
      },
      "torch.atan": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.arctan": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "target_api": "paddle.atan"
      },
      "torch.atan2": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.arctan2": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "target_api": "paddle.atan2"
      },
      "torch.ceil": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.clip": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.clamp": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "target_api": "paddle.clip"
      },
      "torch.conj": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.conj_physical": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "target_api": "paddle.conj"
      },
      "torch.cos": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.cosh": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.count_nonzero": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "params_change": {
                  "dim": "axis"
            }
      },
      "torch.cumsum": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "params_change": {
                  "dim": "axis"
            }
      },
      "torch.cumprod": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.digamma": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.divide": {
            "Matcher": "FuncParamMatcher",
            "Classification": 1,
            "variantCode": [
                  {
                        "param": "rounding_mode",
                        "value": "trunc",
                        "operatorSequence": [
                              {
                                   "level": "C underlying library",
                                   "function": {
                                          "CPU": "DivideKernel",
                                          "GPU": "DivideFunctor"
                                   },
                                   "namespace": {
                                          "CPU": ["phi"],
                                          "GPU": ["phi", "funcs"]
                                   },
                                   "backend": {
                                          "CPU": {
                                                "headers": [
                                                      "#include \"paddle/phi/api/ext/dispatch.h\"",
                                                      "#include \"paddle/phi/backends/cpu/cpu_context.h\"",
                                                      "#include \"paddle/phi/common/bfloat16.h\"",
                                                      "#include \"paddle/phi/common/complex.h\"",
                                                      "#include \"paddle/phi/core/kernel_registry.h\"",
                                                      "#include \"paddle/phi/kernels/cpu/elementwise.h\"",
                                                      "#include \"paddle/phi/kernels/impl/elementwise_kernel_impl.h\""
                                                ],
                                                "funcContext": [],
                                                "sourceCode": "template <typename T, typename Context>\nvoid DivideKernel(const Context& dev_ctx,\n                  const DenseTensor& x,\n                  const DenseTensor& y,\n                  DenseTensor* out) {\n  // allocate memory for out\n  dev_ctx.template Alloc<T>(out);\n  if (x.dims() == y.dims() && std::is_floating_point<T>::value) {\n    SameDimsElementwiseCompute<SameDimsDivideFunctor<CPUContext, T>>()(\n        dev_ctx, x, y, out);\n  } else {\n    auto x_dims = x.dims();\n    auto y_dims = y.dims();\n    if (x_dims.size() >= y_dims.size()) {\n      funcs::ElementwiseCompute<funcs::DivideFunctor<T>, T>(\n          dev_ctx, x, y, funcs::DivideFunctor<T>(), out, -1);\n    } else {\n      funcs::ElementwiseCompute<funcs::InverseDivideFunctor<T>, T>(\n          dev_ctx, x, y, funcs::InverseDivideFunctor<T>(), out, -1);\n    }\n  }\n}\n",
                                                "sequence": [
                                                      {
                                                            "class": "add",
                                                            "loc": ["SameDimsElementwiseCompute<SameDimsDivideFunctor<CPUContext, T>>()(\n        dev_ctx, x, y, out);", "funcs::ElementwiseCompute<funcs::DivideFunctor<T>, T>(\n          dev_ctx, x, y, funcs::DivideFunctor<T>(), out, -1);","funcs::ElementwiseCompute<funcs::InverseDivideFunctor<T>, T>(\n          dev_ctx, x, y, funcs::InverseDivideFunctor<T>(), out, -1);"],
                                                            "code": [
                                                                  "auto* out_data = out->data<T>();",
                                                                  "for (int i = 0; i < out->numel(); ++i) {",
                                                                  "out_data[i] = std::trunc(out_data[i]);",
                                                                  "}"
                                                            ]
                                                      }
                                                ]
                                          },
                                         "GPU": {
                                               "headers": [
                                                     "#include \"paddle/phi/common/bfloat16.h\"",
                                                     "#include \"paddle/phi/common/complex.h\"",
                                                     "#include \"paddle/phi/common/float16.h\"",
                                                     "#include \"paddle/phi/core/enforce.h\"",
                                                     "#include \"paddle/phi/core/hostdevice.h\"",
                                                     "#include \"paddle/phi/core/macros.h\"",
                                                     "#include \"paddle/phi/common/amp_type_traits.h\"",
                                                     "#include \"paddle/phi/common/type_safe_sign_math.h\""
                                               ],
                                               "funcContext": [],
                                               "sourceCode": "template <typename T, typename Enable = void>\nstruct DivideFunctor {\n  inline HOSTDEVICE T operator()(const T a, const T b) const { return a / b; }\n};",
                                               "sequence": [
                                                     {
                                                           "class": "modify",
                                                           "loc": ["return a / b;"],
                                                           "code": [
                                                                 {
                                                                       "a / b" : "std::trunc(a / b)"
                                                                 }
                                                           ]
                                                     }
                                               ]
                                         }
                                   }

                              }
                        ]
                  },
                  {
                        "param": "rounding_mode",
                        "value": "floor",
                        "operatorSequence": [
                              {
                                   "level": "C underlying library",
                                   "function": {
                                          "CPU": "DivideKernel",
                                          "GPU": "DivideFunctor"
                                   },
                                   "namespace": {
                                          "CPU": ["phi"],
                                          "GPU": ["phi", "funcs"]
                                   },
                                   "backend": {
                                          "CPU": {
                                                "headers": [
                                                      "#include \"paddle/phi/api/ext/dispatch.h\"",
                                                      "#include \"paddle/phi/backends/cpu/cpu_context.h\"",
                                                      "#include \"paddle/phi/common/bfloat16.h\"",
                                                      "#include \"paddle/phi/common/complex.h\"",
                                                      "#include \"paddle/phi/core/kernel_registry.h\"",
                                                      "#include \"paddle/phi/kernels/cpu/elementwise.h\"",
                                                      "#include \"paddle/phi/kernels/impl/elementwise_kernel_impl.h\""
                                                ],
                                                "funcContext": [],
                                                "sourceCode": "template <typename T, typename Context>\nvoid DivideKernel(const Context& dev_ctx,\n                  const DenseTensor& x,\n                  const DenseTensor& y,\n                  DenseTensor* out) {\n  // allocate memory for out\n  dev_ctx.template Alloc<T>(out);\n  if (x.dims() == y.dims() && std::is_floating_point<T>::value) {\n    SameDimsElementwiseCompute<SameDimsDivideFunctor<CPUContext, T>>()(\n        dev_ctx, x, y, out);\n  } else {\n    auto x_dims = x.dims();\n    auto y_dims = y.dims();\n    if (x_dims.size() >= y_dims.size()) {\n      funcs::ElementwiseCompute<funcs::DivideFunctor<T>, T>(\n          dev_ctx, x, y, funcs::DivideFunctor<T>(), out, -1);\n    } else {\n      funcs::ElementwiseCompute<funcs::InverseDivideFunctor<T>, T>(\n          dev_ctx, x, y, funcs::InverseDivideFunctor<T>(), out, -1);\n    }\n  }\n}\n",
                                                "sequence": [
                                                      {
                                                            "class": "add",
                                                            "loc": ["SameDimsElementwiseCompute<SameDimsDivideFunctor<CPUContext, T>>()(\n        dev_ctx, x, y, out);", "funcs::ElementwiseCompute<funcs::DivideFunctor<T>, T>(\n          dev_ctx, x, y, funcs::DivideFunctor<T>(), out, -1);","funcs::ElementwiseCompute<funcs::InverseDivideFunctor<T>, T>(\n          dev_ctx, x, y, funcs::InverseDivideFunctor<T>(), out, -1);"],
                                                            "code": [
                                                                  "auto* out_data = out->data<T>();",
                                                                  "for (int i = 0; i < out->numel(); ++i) {",
                                                                  "out_data[i] = std::floor(out_data[i]);",
                                                                  "}"
                                                            ]
                                                      }
                                                ]
                                          },
                                         "GPU": {
                                               "headers": [
                                                     "#include \"paddle/phi/common/bfloat16.h\"",
                                                     "#include \"paddle/phi/common/complex.h\"",
                                                     "#include \"paddle/phi/common/float16.h\"",
                                                     "#include \"paddle/phi/core/enforce.h\"",
                                                     "#include \"paddle/phi/core/hostdevice.h\"",
                                                     "#include \"paddle/phi/core/macros.h\"",
                                                     "#include \"paddle/phi/common/amp_type_traits.h\"",
                                                     "#include \"paddle/phi/common/type_safe_sign_math.h\""
                                               ],
                                               "funcContext": [],
                                               "sourceCode": "template <typename T, typename Enable = void>\nstruct DivideFunctor {\n  inline HOSTDEVICE T operator()(const T a, const T b) const { return a / b; }\n};",
                                               "sequence": [
                                                     {
                                                           "class": "modify",
                                                           "loc": ["return a / b;"],
                                                           "code": [
                                                                 {
                                                                       "a / b" : "std::floor(a / b)"
                                                                 }
                                                           ]
                                                     }
                                               ]
                                         }
                                   }

                              }
                        ]
                  },
                  {
                        "param": "rounding_mode",
                        "value": "round",
                        "operatorSequence": [
                              {
                                   "level": "C underlying library",
                                   "function": {
                                          "CPU": "DivideKernel",
                                          "GPU": "DivideFunctor"
                                   },
                                   "namespace": {
                                          "CPU": ["phi"],
                                          "GPU": ["phi", "funcs"]
                                   },
                                   "backend": {
                                          "CPU": {
                                                "headers": [
                                                      "#include \"paddle/phi/api/ext/dispatch.h\"",
                                                      "#include \"paddle/phi/backends/cpu/cpu_context.h\"",
                                                      "#include \"paddle/phi/common/bfloat16.h\"",
                                                      "#include \"paddle/phi/common/complex.h\"",
                                                      "#include \"paddle/phi/core/kernel_registry.h\"",
                                                      "#include \"paddle/phi/kernels/cpu/elementwise.h\"",
                                                      "#include \"paddle/phi/kernels/impl/elementwise_kernel_impl.h\""
                                                ],
                                                "funcContext": [],
                                                "sourceCode": "template <typename T, typename Context>\nvoid DivideKernel(const Context& dev_ctx,\n                  const DenseTensor& x,\n                  const DenseTensor& y,\n                  DenseTensor* out) {\n  // allocate memory for out\n  dev_ctx.template Alloc<T>(out);\n  if (x.dims() == y.dims() && std::is_floating_point<T>::value) {\n    SameDimsElementwiseCompute<SameDimsDivideFunctor<CPUContext, T>>()(\n        dev_ctx, x, y, out);\n  } else {\n    auto x_dims = x.dims();\n    auto y_dims = y.dims();\n    if (x_dims.size() >= y_dims.size()) {\n      funcs::ElementwiseCompute<funcs::DivideFunctor<T>, T>(\n          dev_ctx, x, y, funcs::DivideFunctor<T>(), out, -1);\n    } else {\n      funcs::ElementwiseCompute<funcs::InverseDivideFunctor<T>, T>(\n          dev_ctx, x, y, funcs::InverseDivideFunctor<T>(), out, -1);\n    }\n  }\n}\n",
                                                "sequence": [
                                                      {
                                                            "class": "add",
                                                            "loc": ["SameDimsElementwiseCompute<SameDimsDivideFunctor<CPUContext, T>>()(\n        dev_ctx, x, y, out);", "funcs::ElementwiseCompute<funcs::DivideFunctor<T>, T>(\n          dev_ctx, x, y, funcs::DivideFunctor<T>(), out, -1);","funcs::ElementwiseCompute<funcs::InverseDivideFunctor<T>, T>(\n          dev_ctx, x, y, funcs::InverseDivideFunctor<T>(), out, -1);"],
                                                            "code": [
                                                                  "auto* out_data = out->data<T>();",
                                                                  "for (int i = 0; i < out->numel(); ++i) {",
                                                                  "out_data[i] = std::round(out_data[i]);",
                                                                  "}"
                                                            ]
                                                      }
                                                ]
                                          },
                                         "GPU": {
                                               "headers": [
                                                     "#include \"paddle/phi/common/bfloat16.h\"",
                                                     "#include \"paddle/phi/common/complex.h\"",
                                                     "#include \"paddle/phi/common/float16.h\"",
                                                     "#include \"paddle/phi/core/enforce.h\"",
                                                     "#include \"paddle/phi/core/hostdevice.h\"",
                                                     "#include \"paddle/phi/core/macros.h\"",
                                                     "#include \"paddle/phi/common/amp_type_traits.h\"",
                                                     "#include \"paddle/phi/common/type_safe_sign_math.h\""
                                               ],
                                               "funcContext": [],
                                               "sourceCode": "template <typename T, typename Enable = void>\nstruct DivideFunctor {\n  inline HOSTDEVICE T operator()(const T a, const T b) const { return a / b; }\n};",
                                               "sequence": [
                                                     {
                                                           "class": "modify",
                                                           "loc": ["return a / b;"],
                                                           "code": [
                                                                 {
                                                                       "a / b" : "std::round(a / b)"
                                                                 }
                                                           ]
                                                     }
                                               ]
                                         }
                                   }

                              }
                        ]
                  }
            ]
      },
      "torch.div": {
            "Matcher": "FuncParamMatcher",
            "Classification": 1,
            "target_api": "paddle.divide",
            "variantCode": [
                  {
                        "param": "rounding_mode",
                        "value": "trunc",
                        "operatorSequence": [
                              {
                                   "level": "C underlying library",
                                   "function": {
                                          "CPU": "DivideKernel",
                                          "GPU": "DivideFunctor"
                                   },
                                   "namespace": {
                                          "CPU": ["phi"],
                                          "GPU": ["phi", "funcs"]
                                   },
                                   "backend": {
                                          "CPU": {
                                                "headers": [
                                                      "#include \"paddle/phi/api/ext/dispatch.h\"",
                                                      "#include \"paddle/phi/backends/cpu/cpu_context.h\"",
                                                      "#include \"paddle/phi/common/bfloat16.h\"",
                                                      "#include \"paddle/phi/common/complex.h\"",
                                                      "#include \"paddle/phi/core/kernel_registry.h\"",
                                                      "#include \"paddle/phi/kernels/cpu/elementwise.h\"",
                                                      "#include \"paddle/phi/kernels/impl/elementwise_kernel_impl.h\""
                                                ],
                                                "funcContext": [],
                                                "sourceCode": "template <typename T, typename Context>\nvoid DivideKernel(const Context& dev_ctx,\n                  const DenseTensor& x,\n                  const DenseTensor& y,\n                  DenseTensor* out) {\n  // allocate memory for out\n  dev_ctx.template Alloc<T>(out);\n  if (x.dims() == y.dims() && std::is_floating_point<T>::value) {\n    SameDimsElementwiseCompute<SameDimsDivideFunctor<CPUContext, T>>()(\n        dev_ctx, x, y, out);\n  } else {\n    auto x_dims = x.dims();\n    auto y_dims = y.dims();\n    if (x_dims.size() >= y_dims.size()) {\n      funcs::ElementwiseCompute<funcs::DivideFunctor<T>, T>(\n          dev_ctx, x, y, funcs::DivideFunctor<T>(), out, -1);\n    } else {\n      funcs::ElementwiseCompute<funcs::InverseDivideFunctor<T>, T>(\n          dev_ctx, x, y, funcs::InverseDivideFunctor<T>(), out, -1);\n    }\n  }\n}\n",
                                                "sequence": [
                                                      {
                                                            "class": "add",
                                                            "loc": ["SameDimsElementwiseCompute<SameDimsDivideFunctor<CPUContext, T>>()(\n        dev_ctx, x, y, out);", "funcs::ElementwiseCompute<funcs::DivideFunctor<T>, T>(\n          dev_ctx, x, y, funcs::DivideFunctor<T>(), out, -1);","funcs::ElementwiseCompute<funcs::InverseDivideFunctor<T>, T>(\n          dev_ctx, x, y, funcs::InverseDivideFunctor<T>(), out, -1);"],
                                                            "code": [
                                                                  "auto* out_data = out->data<T>();",
                                                                  "for (int i = 0; i < out->numel(); ++i) {",
                                                                  "out_data[i] = std::trunc(out_data[i]);",
                                                                  "}"
                                                            ]
                                                      }
                                                ]
                                          },
                                         "GPU": {
                                               "headers": [
                                                     "#include \"paddle/phi/common/bfloat16.h\"",
                                                     "#include \"paddle/phi/common/complex.h\"",
                                                     "#include \"paddle/phi/common/float16.h\"",
                                                     "#include \"paddle/phi/core/enforce.h\"",
                                                     "#include \"paddle/phi/core/hostdevice.h\"",
                                                     "#include \"paddle/phi/core/macros.h\"",
                                                     "#include \"paddle/phi/common/amp_type_traits.h\"",
                                                     "#include \"paddle/phi/common/type_safe_sign_math.h\""
                                               ],
                                               "funcContext": [],
                                               "sourceCode": "template <typename T, typename Enable = void>\nstruct DivideFunctor {\n  inline HOSTDEVICE T operator()(const T a, const T b) const { return a / b; }\n};",
                                               "sequence": [
                                                     {
                                                           "class": "modify",
                                                           "loc": ["return a / b;"],
                                                           "code": [
                                                                 {
                                                                       "a / b" : "std::trunc(a / b)"
                                                                 }
                                                           ]
                                                     }
                                               ]
                                         }
                                   }

                              }
                        ]
                  },
                  {
                        "param": "rounding_mode",
                        "value": "floor",
                        "operatorSequence": [
                              {
                                   "level": "C underlying library",
                                   "function": {
                                          "CPU": "DivideKernel",
                                          "GPU": "DivideFunctor"
                                   },
                                   "namespace": {
                                          "CPU": ["phi"],
                                          "GPU": ["phi", "funcs"]
                                   },
                                   "backend": {
                                          "CPU": {
                                                "headers": [
                                                      "#include \"paddle/phi/api/ext/dispatch.h\"",
                                                      "#include \"paddle/phi/backends/cpu/cpu_context.h\"",
                                                      "#include \"paddle/phi/common/bfloat16.h\"",
                                                      "#include \"paddle/phi/common/complex.h\"",
                                                      "#include \"paddle/phi/core/kernel_registry.h\"",
                                                      "#include \"paddle/phi/kernels/cpu/elementwise.h\"",
                                                      "#include \"paddle/phi/kernels/impl/elementwise_kernel_impl.h\""
                                                ],
                                                "funcContext": [],
                                                "sourceCode": "template <typename T, typename Context>\nvoid DivideKernel(const Context& dev_ctx,\n                  const DenseTensor& x,\n                  const DenseTensor& y,\n                  DenseTensor* out) {\n  // allocate memory for out\n  dev_ctx.template Alloc<T>(out);\n  if (x.dims() == y.dims() && std::is_floating_point<T>::value) {\n    SameDimsElementwiseCompute<SameDimsDivideFunctor<CPUContext, T>>()(\n        dev_ctx, x, y, out);\n  } else {\n    auto x_dims = x.dims();\n    auto y_dims = y.dims();\n    if (x_dims.size() >= y_dims.size()) {\n      funcs::ElementwiseCompute<funcs::DivideFunctor<T>, T>(\n          dev_ctx, x, y, funcs::DivideFunctor<T>(), out, -1);\n    } else {\n      funcs::ElementwiseCompute<funcs::InverseDivideFunctor<T>, T>(\n          dev_ctx, x, y, funcs::InverseDivideFunctor<T>(), out, -1);\n    }\n  }\n}\n",
                                                "sequence": [
                                                      {
                                                            "class": "add",
                                                            "loc": ["SameDimsElementwiseCompute<SameDimsDivideFunctor<CPUContext, T>>()(\n        dev_ctx, x, y, out);", "funcs::ElementwiseCompute<funcs::DivideFunctor<T>, T>(\n          dev_ctx, x, y, funcs::DivideFunctor<T>(), out, -1);","funcs::ElementwiseCompute<funcs::InverseDivideFunctor<T>, T>(\n          dev_ctx, x, y, funcs::InverseDivideFunctor<T>(), out, -1);"],
                                                            "code": [
                                                                  "auto* out_data = out->data<T>();",
                                                                  "for (int i = 0; i < out->numel(); ++i) {",
                                                                  "out_data[i] = std::floor(out_data[i]);",
                                                                  "}"
                                                            ]
                                                      }
                                                ]
                                          },
                                         "GPU": {
                                               "headers": [
                                                     "#include \"paddle/phi/common/bfloat16.h\"",
                                                     "#include \"paddle/phi/common/complex.h\"",
                                                     "#include \"paddle/phi/common/float16.h\"",
                                                     "#include \"paddle/phi/core/enforce.h\"",
                                                     "#include \"paddle/phi/core/hostdevice.h\"",
                                                     "#include \"paddle/phi/core/macros.h\"",
                                                     "#include \"paddle/phi/common/amp_type_traits.h\"",
                                                     "#include \"paddle/phi/common/type_safe_sign_math.h\""
                                               ],
                                               "funcContext": [],
                                               "sourceCode": "template <typename T, typename Enable = void>\nstruct DivideFunctor {\n  inline HOSTDEVICE T operator()(const T a, const T b) const { return a / b; }\n};",
                                               "sequence": [
                                                     {
                                                           "class": "modify",
                                                           "loc": ["return a / b;"],
                                                           "code": [
                                                                 {
                                                                       "a / b" : "std::floor(a / b)"
                                                                 }
                                                           ]
                                                     }
                                               ]
                                         }
                                   }

                              }
                        ]
                  },
                  {
                        "param": "rounding_mode",
                        "value": "round",
                        "operatorSequence": [
                              {
                                   "level": "C underlying library",
                                   "function": {
                                          "CPU": "DivideKernel",
                                          "GPU": "DivideFunctor"
                                   },
                                   "namespace": {
                                          "CPU": ["phi"],
                                          "GPU": ["phi", "funcs"]
                                   },
                                   "backend": {
                                          "CPU": {
                                                "headers": [
                                                      "#include \"paddle/phi/api/ext/dispatch.h\"",
                                                      "#include \"paddle/phi/backends/cpu/cpu_context.h\"",
                                                      "#include \"paddle/phi/common/bfloat16.h\"",
                                                      "#include \"paddle/phi/common/complex.h\"",
                                                      "#include \"paddle/phi/core/kernel_registry.h\"",
                                                      "#include \"paddle/phi/kernels/cpu/elementwise.h\"",
                                                      "#include \"paddle/phi/kernels/impl/elementwise_kernel_impl.h\""
                                                ],
                                                "funcContext": [],
                                                "sourceCode": "template <typename T, typename Context>\nvoid DivideKernel(const Context& dev_ctx,\n                  const DenseTensor& x,\n                  const DenseTensor& y,\n                  DenseTensor* out) {\n  // allocate memory for out\n  dev_ctx.template Alloc<T>(out);\n  if (x.dims() == y.dims() && std::is_floating_point<T>::value) {\n    SameDimsElementwiseCompute<SameDimsDivideFunctor<CPUContext, T>>()(\n        dev_ctx, x, y, out);\n  } else {\n    auto x_dims = x.dims();\n    auto y_dims = y.dims();\n    if (x_dims.size() >= y_dims.size()) {\n      funcs::ElementwiseCompute<funcs::DivideFunctor<T>, T>(\n          dev_ctx, x, y, funcs::DivideFunctor<T>(), out, -1);\n    } else {\n      funcs::ElementwiseCompute<funcs::InverseDivideFunctor<T>, T>(\n          dev_ctx, x, y, funcs::InverseDivideFunctor<T>(), out, -1);\n    }\n  }\n}\n",
                                                "sequence": [
                                                      {
                                                            "class": "add",
                                                            "loc": ["SameDimsElementwiseCompute<SameDimsDivideFunctor<CPUContext, T>>()(\n        dev_ctx, x, y, out);", "funcs::ElementwiseCompute<funcs::DivideFunctor<T>, T>(\n          dev_ctx, x, y, funcs::DivideFunctor<T>(), out, -1);","funcs::ElementwiseCompute<funcs::InverseDivideFunctor<T>, T>(\n          dev_ctx, x, y, funcs::InverseDivideFunctor<T>(), out, -1);"],
                                                            "code": [
                                                                  "auto* out_data = out->data<T>();",
                                                                  "for (int i = 0; i < out->numel(); ++i) {",
                                                                  "out_data[i] = std::round(out_data[i]);",
                                                                  "}"
                                                            ]
                                                      }
                                                ]
                                          },
                                         "GPU": {
                                               "headers": [
                                                     "#include \"paddle/phi/common/bfloat16.h\"",
                                                     "#include \"paddle/phi/common/complex.h\"",
                                                     "#include \"paddle/phi/common/float16.h\"",
                                                     "#include \"paddle/phi/core/enforce.h\"",
                                                     "#include \"paddle/phi/core/hostdevice.h\"",
                                                     "#include \"paddle/phi/core/macros.h\"",
                                                     "#include \"paddle/phi/common/amp_type_traits.h\"",
                                                     "#include \"paddle/phi/common/type_safe_sign_math.h\""
                                               ],
                                               "funcContext": [],
                                               "sourceCode": "template <typename T, typename Enable = void>\nstruct DivideFunctor {\n  inline HOSTDEVICE T operator()(const T a, const T b) const { return a / b; }\n};",
                                               "sequence": [
                                                     {
                                                           "class": "modify",
                                                           "loc": ["return a / b;"],
                                                           "code": [
                                                                 {
                                                                       "a / b" : "std::round(a / b)"
                                                                 }
                                                           ]
                                                     }
                                               ]
                                         }
                                   }

                              }
                        ]
                  }
            ]
      },
      "torch.equal": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.erf": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.exp": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.expm1": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.floor": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.floor_divide": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.greater_equal": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.ge": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "target_api": "paddle.greater_equal"
      },
      "torch.kron": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "target_api": "paddle.kron"
      },
      "torch.less_equal": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.le": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "target_api": "paddle.less_equal"
      },
      "torch.lgamma": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.log": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.log10": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.log2": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.logcumsumexp": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "params_change": {
                  "dim": "axis"
            }
      },
      "torch.logical_and": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.logical_not": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.logical_or": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.logical_xor": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.logit": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.bitwise_and": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.bitwise_not": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.bitwise_or": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.bitwise_xor": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "logsumexp": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "params_change": {
                  "dim": "axis"
            }
      },
      "torch.max": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "params_change": {
                  "dim": "axis"
            }
      },
      "torch.maximum": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.mean": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "params_change": {
                  "dim": "axis"
            }
      },
      "torch.median": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "params_change": {
                  "dim": "axis"
            }
      },
      "torch.nanmedian": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "params_change": {
                  "dim": "axis"
            }
      },
      "torch.min": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "params_change": {
                  "dim": "axis"
            }
      },
      "torch.minimum": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.mm": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.inner": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.outer": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.multiply": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.mul": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "target_api": "paddle.multiply"
      },
      "torch.neg": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.negative": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "target_api": "paddle.neg"
      },
      "torch.not_equal": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "target_api": "paddle.neg"
      },
      "torch.ne": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "target_api": "paddle.not_equal"
      },
      "torch.pow": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.prod": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "params_change": {
                  "dim": "axis"
            }
      },
      "torch.reciprocal": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.round": {
            "Matcher": "DirectMatcher",
            "Classification": 1,
            "variantCode": [
                  {
                        "param": "decimals",
                        "operatorSequence": [
                              {
                                    "level": "C underlying library",
                                    "function": {
                                          "CPU": "RoundFunctor",
                                          "GPU": "CudaRoundFunctor"
                                    },
                                    "namespace": {
                                          "CPU": ["phi"],
                                          "GPU": ["phi", "funcs"]
                                    },
                                    "backend": {
                                         "CPU": {
                                             "headers": [
                                                   "#include <glog/logging.h>",
                                                   "#include <algorithm>",
                                                   "#include <cmath>",
                                                   "#include <memory>",
                                                   "#include <string>",
                                                   "#include <unordered_set>",
                                                   "#include <utility>",
                                                   "#include <vector>",
                                                   "#ifndef _USE_MATH_DEFINES",
                                                   "#define _USE_MATH_DEFINES \n#endif\n",
                                                   "#include <type_traits>",
                                                   "#include \"paddle/phi/common/amp_type_traits.h\"",
                                                   "#include \"paddle/phi/common/bfloat16.h\"",
                                                   "#include \"paddle/phi/common/float16.h\"",
                                                   "#include \"paddle/phi/core/dense_tensor.h\"",
                                                   "#include \"paddle/phi/core/enforce.h\"",
                                                   "#include \"paddle/phi/kernels/funcs/eigen/common.h\"",
                                                   "#include \"paddle/phi/kernels/funcs/eigen/extensions.h\""
                                             ],
                                             "funcContext": [],
                                             "sourceCode": "template <typename T>\nstruct RoundFunctor : public BaseActivationFunctor<T> {\n  template <typename Device, typename X, typename Out>\n  void operator()(Device d, X x, Out out) const {\n    out.device(d) = x.round();\n  }\n};",
                                             "sequence": [
                                                   {
                                                      "class": "add",
                                                      "loc": ["void operator()(Device d, X x, Out out) const {"],
                                                      "code": [
                                                            "T scale = std::pow(10, decimals);"
                                                      ]
                                                   },
                                                   {
                                                      "class": "modify",
                                                      "loc": ["x.round()"],
                                                      "code":[
                                                            {
                                                                "x.round()": "(x * scale).round() / scale"
                                                            }
                                                      ]
                                                   }
                                             ]
                                         },
                                         "GPU": {
                                             "headers": [
                                                   "#include <glog/logging.h>",
                                                   "#include <algorithm>",
                                                   "#include <cmath>",
                                                   "#include <memory>",
                                                   "#include <string>",
                                                   "#include <unordered_set>",
                                                   "#include <utility>",
                                                   "#include <vector>",
                                                   "#ifndef _USE_MATH_DEFINES",
                                                   "#define _USE_MATH_DEFINES \n#endif\n",
                                                   "#include <type_traits>",
                                                   "#include \"paddle/phi/common/amp_type_traits.h\"",
                                                   "#include \"paddle/phi/common/bfloat16.h\"",
                                                   "#include \"paddle/phi/common/float16.h\"",
                                                   "#include \"paddle/phi/core/dense_tensor.h\"",
                                                   "#include \"paddle/phi/core/enforce.h\"",
                                                   "#include \"paddle/phi/kernels/funcs/eigen/common.h\"",
                                                   "#include \"paddle/phi/kernels/funcs/eigen/extensions.h\""
                                             ],
                                             "funcContext": [],
                                             "sourceCode": "#if defined(__NVCC__) || defined(__HIPCC__) || defined(__xpu__)\n  template <typename T>\nstruct CudaRoundFunctor : public BaseActivationFunctor<T> {\n  using MPType = typename phi::dtype::MPTypeTrait<T>::Type;\n\n  // round(x) = round(x)\n  __device__ __forceinline__ T operator()(const T arg_x) const {\n    MPType x = static_cast<MPType>(arg_x);\n    return static_cast<T>(round(x));\n  }\n}; \n#endif\n",
                                             "sequence": [
                                                   {
                                                      "class": "add",
                                                      "loc": ["__device__ __forceinline__ T operator()(const T arg_x) const {"],
                                                      "code": [
                                                            "MPType scale = pow(10.0, decimals);"
                                                      ]
                                                   },
                                                   {
                                                      "class": "modify",
                                                      "loc": ["static_cast<T>(round(x))"],
                                                      "code":[
                                                            {
                                                                "round(x)": "round(x * scale) / scale"
                                                            }
                                                      ]
                                                   }
                                             ]
                                         }
                                    }
                              }

                        ]
                  }
            ]
      },
      "torch.rsqrt": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.sign": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.sgn": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.sin": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.sinh": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.sqrt": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.square": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.std": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "params_change": {
                  "dim": "axis"
            }
      },
      "torch.subtract": {
            "Matcher": "FuncParamMatcher",
            "Classification": 1,
            "variantCode": [
                  {
                        "param": "decimals",
                        "level": "C underlying library",
                        "code": {
                              "CPU": "",
                              "CUDA": ""
                        }
                  }
            ]
      },
      "torch.sub": {
            "Matcher": "FuncParamMatcher",
            "Classification": 1,
            "target_api": "paddle.subtract",
            "variantCode": [
                  {
                        "param": "decimals",
                        "level": "C underlying library",
                        "code": {
                              "CPU": "",
                              "CUDA": ""
                        }
                  }
            ]
      },
      "torch.remainder": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.sum": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "params_change": {
                  "dim": "axis"
            }
      },
      "torch.tan": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.tanh": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.trace": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.var": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "params_change": {
                  "dim": "axis"
            }
      },
      "torch.diagonal": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "params_change": {
                  "dim1": "axis1",
                  "dim2": "axis2"
            }
      },
      "torch.trunc": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.fix": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "target_api": "paddle.fix"
      },
      "torch.frac": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.log1p": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.take_along_dim": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "target_api": "paddle.take_along_axis",
            "params_change": {
                  "dim": "axis"
            }
      },
      "torch.lerp": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.diff": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "params_change": {
                  "dim": "axis"
            }
      },
      "torch.rad2deg": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.deg2rad": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.gcd": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.lcm": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.erfinv": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.asinh": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.arcsinh": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "target_api": "paddle.sinh"
      },
      "torch.atanh": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.arctanh": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "target_api": "paddle.atanh"
      },
      "torch.rand": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.randn": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.cat": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "target_api": "paddle.concat",
            "params_change": {
                  "dim": "axis"
            }
      },
      "torch.numel": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.full": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.full_like": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.empty_like": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.empty": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.reshape": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.nonzero": {
            "Matcher": "OEDAMatcher",
            "Classification": 5,
            "variantCode": [
            ]
      },
      "torch.split": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.squeeze": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.stack": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "params_change": {
                  "dim": "axis"
            }
      },
      "torch.t": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.unsqueeze": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.where": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.unbind": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.transpose": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.chunk": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "params_change": {
                  "dim": "axis"
            }
      },
      "torch.gather": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "params_change": {
                  "dim": "axis"
            }
      },
      "torch.index_select": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.masked_select": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.get_default_dtype": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.set_default_dtype": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.tensor": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "target_api": "paddle.to_tensor"
      },
      "torch.argmax": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.argmin": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.real": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.permute": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "target_api": "paddle.transpose"
      },
      "torch.nn.functional.layer_norm": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "params_change": {
                  "eps": "epslion"
            }
      },
      "torch.arrange": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.zeros": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.dropout": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "target_api": "paddle.nn.functional.dropout"
      },
      "torch.ones": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.zero_": {
            "Matcher": "DirectMatcher",
            "classification": 0,
            "target_api": "paddle.zeros_like"
      },
      "torch.tensor.zero_": {
            "Matcher": "DirectMatcher",
            "classification": 0,
            "target_api": "paddle.zeros_like"
      },
      "torch.flatten": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "params_change": {
                  "start_dim": "start_axis",
                  "end_dim": "end_axis"
            }
      },
      "torch.float": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "target_api": "paddle.float64"
      },
      "torch.finfo": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.softmax": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "target_api": "paddle.nn.functional.softmax",
            "params_change": {
                  "dim": "axis"
            }
      },
      "torch.onnx.symbolic_opset9.size": {},
      "torch.einsum": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.no_grad": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.load": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.sigmoid": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "target_api": "paddle.nn.functional.sigmoid"
      },
      "torch.fill_": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "target_api": "paddle.Tensor.fill_"
      },
      "torch.zeros_like": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.from_numpy": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "target_api": "paddle.to_tensor"
      },
      "torch.layer_norm": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.detach": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.bmm": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.long": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "target_api": "paddle.int64"
      },
      "torch.clone": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.FloatTensor": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "target_api": "paddle.to_tensor",
            "default_kwargs": {
                  "dtype": "float32"
            }
      },
      "torch.asarray": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "target_api": "paddle.to_tensor"
      },
      "torch.flip": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "params_change": {
                  "dim": "axis"
            }
      },
      "torch.masked_fill": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "target_api": "paddle.where",
            "params_change": {
                  "mask": "condition",
                  "value": "y"
            }
      },
      "torch.cpu": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "target_api": "paddle.Tensor.cpu"
      },
      "torch.nn.Sequential": {
            "Matcher": "SequentialMatcher",
            "Classification": 0
      },
      "torch.norm": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.repeat_interleave": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "params_change": {
                  "dim": "axis"
            }
      },
      "torch.isinf": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.as_tensor": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "target_api": "paddle.to_tensor"
      },
      "torch.ones_like": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.bool": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.Tensor": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.linspace": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.int": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "target_api": "paddle.int16"
      },
      "torch.isnan": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.eq": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "target_api": "paddle.equal"
      },
      "torch.relu": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "target_api": "paddle.nn.functional.relu"
      },
      "torch.Size": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "target_api": "paddle.shape"
      },
      "torch.tril": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.dtype": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.save": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.log_softmax": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "params_change": {
                  "dim": "axis"
            }
      },
      "torch.broadcast_to": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.concatenate": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "params_change": {
                  "dim": "axis"
            }
      },
      "torch.nn.modules": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "target_api": "paddle.nn.Layer.sublayers"
      },
      "torch.nn.functional.pad": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch._assert": {
            "Matcher": "AssertMatcher",
            "Classification": 0,
            "target_api": "assert"
      },
      "torch.topk": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "params_change": {
                  "dim": "axis"
            }
      },
      "torch.LongTensor": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "target_api": "paddle.int64"
      },
      "torch.meshgrid": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.group_norm": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "target_api": "paddle.nn.functional.group_norm"
      },
      "torch.device": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "target_api": "str"
      },
      "torch.nn.functional.interpolate": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "default_kwargs": {
                  "data_format": "'NCW'"
            }
      },
      "torch.floor_": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "target_api": "paddle.base.core.eager.ops.floor_"
      },
      "torch.roll": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "params_change": {
                  "dim": "axis"
            }
      },
      "torch.fmod": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "target_api": "paddle.floor_mod"
      },
      "torch.unique": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.is_tensor": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.sort": {
            "Matcher": "OSSMatcher",
            "Classification": 0,
            "params_change": {
                  "dim": "axis"
            },
            "variantCode": [
                  {
                        "param": "stable",
                        "level": "C underlying library",
                        "code": {
                              "CPU": "",
                              "CUDA": ""
                        }
                  }
            ]
      },
      "torch.diag": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.nn.functional.smooth_l1_loss": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.nn.functional.unfold": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.nn.functional.grid_sample": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.abs_": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.std_mean": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "target_api": "paddle.std"
      },
      "torch.nn.functional.glu": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.nn.functional.gumbel_softmax": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.pixel_shuffle": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.nansum": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.bincount": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.scatter_reduce": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.rand_like": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "target_api": "paddle.randint_like"
      },
      "torch.logspace": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.nn.LSTM": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "params_change": {
                  "batch_first": "time_major",
                  "bias": [
                        "bias_ih_attr",
                        "bias_hh_attr"
                  ]
            }
      },
      "torch.kthvalue": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.nn.LSTMCell": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.logaddexp": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.clamp_min": {
            "Matcher": "UEHSMatcher",
            "Classification": 3,
            "variantCode": []
      },
      "torch.multinomial": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.as_strided": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.eye": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.narrow": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.nn.functional.cross_entropy": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.cdist": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.triu": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.randint": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.is_floating_point": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.nn.functional.silu": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.double": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "target_api": "paddle.Tensor.astype",
            "default_kwargs": {
                  "dtype": "float64"
            }
      },
      "torch.logsumexp": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "params_change": {
                  "dim": "axis"
            }
      },
      "torch.poisson": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.cosine_similarity": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.ctc_loss": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.randperm": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.nn.functional.normalize": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "params_change": {
                  "dim": "axis",
                  "eps": "epsilon"
            }
      },
      "torch.conv_transpose1d": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "params_change": {
                  "bias": "bias_attr"
            }
      },
      "torch.frexp": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.bucketize": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "params_change": {
                  "boundaries": "sorted_sequence"
            }
      },
      "torch.cross": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.binary_cross_entropy_with_logits": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "params_change": {
                  "input": "logits",
                  "tatget": "label"
            }
      },
      "torch.nn.functional.linear": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.autocast": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.nn.functional.dropout2d": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.nn.functional.avg_pool2d": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.nn.functional.upsample": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.nn.functional.gelu": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.nn.functional.mish": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.mode": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.swapaxes": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "target_api": "paddle.transpose"
      },
      "torch.nn.AdaptiveLogSoftmaxWithLoss": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.conv_transpose2d": {
            "Matcher": "DirectMatcher",
            "Classification": 1,
            "target_api": "paddle.nn.functional.conv2d_transpose",
            "params_change": {
                  "bias": "bias_attr"
            }
      },
      "torch.view_as_complex": {
            "Matcher": "FSCSMatcher",
            "Classification": 2,
            "variantCode": ""
      },
      "torch.tile": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.bernoulli": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.nn.Module.load_state_dict": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "target_api": "paddle.nn.Layer.set_state_dict"
      },
      "torch.nn.init.constant_": {
            "Matcher": "InitializerMatcher",
            "Classification": 0,
            "params_change": {
                  "val": "value"
            },
            "target_api": "paddle.nn.initializer.Constant"
      },
      "torch.nn.init.normal_": {
            "Matcher": "InitializerMatcher",
            "Classification": 0,
            "target_api": "paddle.nn.initializer.Normal"
      },
      "torch.nn.Module": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "target_api": "paddle.nn.Layer"
      },
      "torch.nn.Module.modules": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "target_api": "paddle.nn.Layer.sublayers"
      },
      "torch.nn.Dropout": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.nn.init.kaiming_normal_": {
            "Matcher": "InitializerMatcher",
            "Classification": 0,
            "params_change": {
                  "a": "negative_slope"
            },
            "target_api": "paddle.nn.initializer.KaimingNormal",
            "variantCode": [
                  {
                        "param": "mode",
                        "value": "fan_out",
                        "operatorSequence": [
                              {
                                    "level": "python underlying library",
                                    "function": "forward",
                                    "sequence": [
                                          {
                                                "class": "modify",
                                                "loc": ["fan_in = f_in if self._fan_in is None else self._fan_in"],
                                                "code": [
                                                      {
                                                            "else self._fan_in": "else f_out"
                                                      }
                                                ]
                                          }
                                    ]

                              }
                        ]
                  }
            ]
      },
      "torch.nn.init.kaiming_uniform_": {
            "Matcher": "InitializerMatcher",
            "Classification": 0,
            "params_change": {
                  "a": "negative_slope"
            },
            "target_api": "paddle.nn.initializer.KaimingUniform",
            "variantCode": [
                  {
                        "param": "mode",
                        "value": "fan_out",
                        "operatorSequence": [
                              {
                                    "level": "python underlying library",
                                    "function": "forward",
                                    "sequence": [
                                          {
                                                "class": "modify",
                                                "loc": ["fan_in = f_in if self._fan_in is None else self._fan_in"],
                                                "code": [
                                                      {
                                                            "else self._fan_in": "else f_out"
                                                      }
                                                ]
                                          }
                                    ]

                              }
                        ]
                  }
            ]

      },
      "torch.nn.init.zeros_": {
            "Matcher": "InitializerMatcher",
            "Classification": 4,
            "target_api": "paddle.nn.initializer.Constant",
            "default_kwargs": {
                  "value": "0"
            }
      },
      "torch.nn.init.ones_": {
            "Matcher": "InitializerMatcher",
            "Classification": 4,
            "target_api": "paddle.nn.initializer.Constant",
            "default_kwargs": {
                  "value": "1"
            }
      },
      "torch.nn.functional.relu": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.nn.functional.adaptive_avg_pool2d": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.arange": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.int32": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.nn.functional.hardtanh": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.nn.functional.dropout": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.nn.RNN": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "target_api": "paddle.nn.SimpleRNN",
            "params_change": {
                  "nonlinearity": "activation",
                  "bidirectional": "direction",
                  "bias": [
                        "bias_ih_attr",
                        "bias_hh_attr"
                  ],
                  "batch_first": "time_major"
            }
      },
      "torch.nn.functional.log_softmax": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "params_change": {
                  "dim": "axis"
            }
      },
      "torch.cuda.is_available": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "target_api": "paddle.is_compiled_with_cuda"
      },
      "torch.nn.functional.max_pool1d": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.nn.init.trunc_normal_": {
            "Matcher": "InitializerMatcher",
            "Classification": 0,
            "target_api": "paddle.nn.initializer.TruncatedNormal",
            "variantCode": [
                  {
                        "param": "a",
                        "operatorSequence": [
                              {
                                    "level": "python underlying library",
                                    "function": "forward",
                                    "sequence": [
                                          {
                                                "class": "add",
                                                "loc": ["out_var = _C_ops.truncated_gaussian_random(\n                var.shape,\n                self._mean,\n                self._std_dev,\n                self._seed,\n                out_dtype,\n                _current_expected_place(),\n            )"],
                                                "code": [
                                                      "lower_bound = self._mean + a * self._std_dev",
                                                      "out_var = paddle.clip(out_var, min = lower_bound)"
                                                ]
                                          }
                                    ]

                              }
                        ]
                  },
                  {
                        "param": "b",
                        "operatorSequence": [
                              {
                                    "level": "python underlying library",
                                    "function": "forward",
                                    "sequence": [
                                          {
                                                "class": "add",
                                                "loc": ["out_var = _C_ops.truncated_gaussian_random(\n                var.shape,\n                self._mean,\n                self._std_dev,\n                self._seed,\n                out_dtype,\n                _current_expected_place(),\n            )"],
                                                "code": [
                                                      "upper_bound = self._mean + b * self._std_dev",
                                                      "out_var = paddle.clip(out_var, max = upper_bound)"
                                                ]
                                          }
                                    ]

                              }
                        ]
                  }
            ]
      },
      "torch.nn.functional.max_pool2d": {
            "Matcher": "DirectMatcher",
            "Classification": 1,
            "params_change": {
                  "return_indices": "return_mask"
            }
      },
      "torchvision.get_image_backend": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torchvision.set_image_backend": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torchvision.models.alexnet": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torchvision.models.AlexNet": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torchvision.models.DenseNet": {
            "Matcher": "DirectMatcher",
            "Classification": 1,
            "params_change": {
                  "growth_rate": "layers",
                  "drop_rate": "dropout"
            }
      },
      "torchvision.models.densenet121": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "params_change": {
                  "weights": "pretrained"
            }
      },
      "torchvision.models.densenet161": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "params_change": {
                  "weights": "pretrained"
            }
      },
      "torchvision.models.densenet169": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "params_change": {
                  "weights": "pretrained"
            }
      },
      "torchvision.models.densenet201": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "params_change": {
                  "weights": "pretrained"
            }
      },
      "torchvision.models.resnet18": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "params_change": {
                  "weights": "pretrained"
            }
      },
      "torchvision.models.resnet34": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "params_change": {
                  "weights": "pretrained"
            }
      },
      "torchvision.models.resnet50": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "params_change": {
                  "weights": "pretrained"
            }
      },
      "torchvision.models.resnet101": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "params_change": {
                  "weights": "pretrained"
            }
      },
      "torchvision.models.resnet152": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "params_change": {
                  "weights": "pretrained"
            }
      },
      "torchvision.models.vgg11": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "params_change": {
                  "weights": "pretrained"
            }
      },
      "torchvision.models.vgg11_bn": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "params_change": {
                  "weights": "pretrained"
            },
            "default_kwargs": {
                  " batch_norm": "Ture"
            }
      },
      "torchvision.models.vgg13": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "params_change": {
                  "weights": "pretrained"
            }
      },
      "torchvision.models.vgg13_bn": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "params_change": {
                  "weights": "pretrained"
            },
            "default_kwargs": {
                  " batch_norm": "Ture"
            }
      },
      "torchvision.models.vgg16": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "params_change": {
                  "weights": "pretrained"
            }
      },
      "torchvision.models.vgg16_bn": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "params_change": {
                  "weights": "pretrained"
            },
            "default_kwargs": {
                  " batch_norm": "Ture"
            }
      },
      "torchvision.models.vgg19": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "params_change": {
                  "weights": "pretrained"
            }
      },
      "torchvision.models.vgg19_bn": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "params_change": {
                  "weights": "pretrained"
            },
            "default_kwargs": {
                  " batch_norm": "Ture"
            }
      },
      "torchvision.models.SqueezeNet": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torchvision.models.squeezenet1_0": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "params_change": {
                  "weights": "pretrained"
            }
      },
      "torchvision.models.squeezenet1_1": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "params_change": {
                  "weights": "pretrained"
            }
      },
      "torchvision.models.Inception3": {
            "Matcher": "DirectMatcher",
            "target_api": "paddle.vision.models.InceptionV3",
            "Classification": 0
      },
      "torchvision.models.inception_v3": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "params_change": {
                  "weights": "pretrained"
            }
      },
      "torchvision.datasets.CIFAR10": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torchvision.datasets.CIFAR100": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torchvision.datasets.FashionMNIST": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torchvision.datasets.Flowers102": {
            "Matcher": "DirectMatcher",
            "target_api": "paddle.vision.datasets.Flowers",
            "Classification": 0
      },
      "torchvision.datasets.MNIST": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torchvision.transforms.functional.adjust_brightness": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torchvision.transforms.functional.adjust_contrast": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torchvision.transforms.v2.functional.adjust_brightness": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torchvision.transforms.v2.functional.adjust_contrast": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torchvision.transforms.functional.adjust_hue": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torchvision.transforms.v2.functional.adjust_hue": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torchvision.transforms.functional.affine": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torchvision.transforms.functional.crop": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torchvision.transforms.v2.functional.crop": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.nn.TransformerEncoderLayer": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "params_change": {
                  "norm_first": "normalize_before"
            }
      },
      "torch.nn.TransformerEncoder": {
            "Matcher": "FuncParamMatcher",
            "Classification": 1,
            "variantCode": [
                  {
                        "param": "enable_nested_tensor",
                        "value": "False",
                        "operatorSequence": [
                              {
                                    "level": "python underlying library",
                                    "function": "forward",
                                    "sequence": [
                                          {
                                                "class": "add",
                                                "loc": ["):\n"],
                                                "code": "src_mask = None   \n"
                                          }
                                    ]
                              }]}]},
      "torch.nn.functional.softmax": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "params_change": {
                  "dim": "axis"
            }
      },
      "torch.nn.init.xavier_uniform_": {
            "Matcher": "InitializerMatcher",
            "Classification": 1,
            "target_api": "paddle.nn.initializer.XavierUniform"
      },
      "torch.nn.Parameter": {
            "Matcher": "tensorParamMatcher",
            "Classification": 0
      },
      "torch.nn.Flatten": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.view": {
            "Matcher": "ViewMatcher",
            "Classification": 0,
            "target_api": "paddle.Tensor.reshape"
      },
      "torch.Tensor.view": {
            "Matcher": "ViewMatcher",
            "Classification": 0,
            "target_api": "paddle.Tensor.reshape"
      },
      "torch.size": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "target_api": "paddle.Tensor.shape"
      },
      "torch.nn.add_module": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "target_api": "paddle.nn.Layer.add_sublayer"
      },
      "torch.nn.MultiheadAttention":{
            "Matcher": "FuncParamMatcher",
            "Classification": 1,
            "params_change": {
                  "bias": "bias_attr"
            },
            "variantCode": [
                  {
                        "param": "add_bias_kv",
                        "value": "True",
                        "operatorSequence": [
                              {
                                    "level": "python underlying library",
                                    "function": "__init__",
                                    "sequence": [
                                          {
                                                "class": "add",
                                                "loc": ["super().__init__()\n"],
                                                "code": "self.bias_k = self.create_parameter(shape=[embed_dim], default_initializer=paddle.nn.initializer.Constant(value=0.0))\n"
                                          },
                                          {
                                                "class": "add",
                                                "loc": ["super().__init__()\n"],
                                                "code": "self.bias_v = self.create_parameter(shape=[embed_dim], default_initializer=paddle.nn.initializer.Constant(value=0.0))\n"
                                          }
                                    ]
                              },
                              {
                                    "level": "python underlying library",
                                    "function": "compute_kv",
                                    "sequence": [
                                          {
                                                "class": "add",
                                                "loc": ["k = self.k_proj(key)\n"],
                                                "code": "k = k + self.bias_k\n"
                                          },
                                          {
                                                "class": "add",
                                                "loc": ["v = self.v_proj(value)\n"],
                                                "code": "v = v + self.bias_v\n"
                                          }
                                    ]
                              }
                        ]
                  },
                  {
                        "param": "add_zero_attn",
                        "value": "True",
                        "operatorSequence": [
                              {
                                    "level": "python underlying library",
                                    "function": "forward",
                                    "sequence": [
                                          {
                                                "class": "add",
                                                "loc": ["product = paddle.matmul(\n            x=q * (self.head_dim**-0.5), y=k, transpose_y=True\n        )\n"],
                                                "code": "zero_attn = paddle.zeros(list(product.shape[:-1]) + [1], dtype=product.dtype)\n"
                                          },
                                          {
                                                "class": "add",
                                                "loc": ["product = paddle.matmul(\n            x=q * (self.head_dim**-0.5), y=k, transpose_y=True\n        )\n"],
                                                "code": "product = paddle.concat([product, zero_attn], axis=-1)\n"
                                          }
                                    ]
                              }
                        ]

                  }
            ]
      },
      "torch.tensor_split": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "target_api": "paddle.split",
            "params_change": {
                  "tensor_indices_or_sections": "num_or_sections",
                  "indices": "num_or_sections",
                  "dim": "axis"
            }
      },
      "torch.matmul": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.nn.init.orthogonal_": {
            "Matcher": "InitializerMatcher",
            "Classification": 0,
            "target_api": "paddle.nn.initializer.Orthogonal"
      },
      "torch.nn.init.xavier_normal_": {
            "Matcher": "InitializerMatcher",
            "Classification": 0,
            "variantCode": [
                  {
                        "param": "gain",
                        "operatorSequence": [
                              {
                                    "level": "python underlying library",
                                    "function": "forward",
                                    "sequence": [
                                          {
                                                "class": "modify",
                                                "loc": ["std = math.sqrt(2.0 / float(fan_in + fan_out))"],
                                                "code": [
                                                      {
                                                            "math.sqrt(2.0 / float(fan_in + fan_out))": "gain * math.sqrt(2.0 / float(fan_in + fan_out))"
                                                      }
                                                ]
                                          }
                                    ]

                              }
                        ]
                  }
            ]
      },
      "torch.nn": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "target_api": "paddle.nn"
      },
      "torch.repeat": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "target_api": "paddle.tile"
      },
      "torch.float32": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.nn.parameter.Parameter": {
            "Matcher": "tensorParamMatcher",
            "Classification": 0
      },
      "torch.is_storage": {
            "Matcher": "Unsupported",
            "Classification": -1,
            "Issue": "No single or combined operator equivalent available"
      },
      "torch.is_complex": {
            "Matcher": "Unsupported",
            "Classification": -1,
            "Issue": "No single or combined operator equivalent available"
      },
      "torch.is_nonzero": {
            "Matcher": "Unsupported",
            "Classification": -1,
            "Issue": "No single or combined operator equivalent available"
      },
      "torch.set_default_device": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "target_api": "paddle.set_device"
      },
      "torch.get_default_device": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "target_api": "paddle.get_device"
      },
      "torch.set_default_tensor_type": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "target_api": "paddle.set_default_dtype"
      },
      "torch.set_printoptions": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.set_flush_denormal": {
            "Matcher": "Unsupported",
            "Classification": -1,
            "Issue": "No single or combined operator equivalent available"
      },
      "torch.sparse_coo_tensor": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.sparse_csr_tensor": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "target_api": "paddle.sparse.sparse_coo_tensor"
      },
      "torch.sparse_bsr_tensor": {
            "Matcher": "Unsupported",
            "Classification": -1,
            "Issue": "No single or combined operator equivalent available"
      },
      "paddle.sparse.sparse_coo_tensor": {
            "Matcher": "Unsupported",
            "Classification": -1,
            "Issue": "No single or combined operator equivalent available"
      },
      "torch.sparse_bsc_tensor": {
            "Matcher": "Unsupported",
            "Classification": -1,
            "Issue": "No single or combined operator equivalent available"
      },
      "torch.from_file": {
            "Matcher": "Unsupported",
            "Classification": -1,
            "Issue": "No single or combined operator equivalent available"
      },
      "torch.from_dlpack": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "target_api": "paddle.utils.dlpack.from_dlpack"
      },
      "torch.frombuffer": {
            "Matcher": "Unsupported",
            "Classification": -1,
            "Issue": "No single or combined operator equivalent available"
      },
      "torch.empty_strided": {
            "Matcher": "Unsupported",
            "Classification": -1,
            "Issue": "No single or combined operator equivalent available"
      },
      "torch.quantize_per_tensor": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "target_api": "paddle.quant"
      },
      "torch.dequantize": {
            "Matcher": "OCSMatcher",
            "Classification": 2,
            "operatorSequence": [
                  {
                        "function": "dquantile",
                        "params": [
                              "input"
                        ],
                        "ReturnSequence": {
                              "return": "(input / 1.0 + 0.0).astype('float32') "
                        }
                  }
            ]
      },
      "torch.complex": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.polar": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "target_api": "paddle.to_tensor"
      },
      "torch.heaviside": {
            "Matcher": "OCSMatcher",
            "Classification": 2,
            "operatorSequence": [
                  {
                        "function": "heaviside",
                        "params": [
                              "input",
                              "value"
                        ],
                        "ReturnSequence": {
                              "return": "torch.where(input < 0, torch.zeros_like(input), torch.where(input > 0, torch.ones_like(input), value))"
                        }
                  }
            ]
      },
      "torch.adjoint": {
            "Matcher": "OCSMatcher",
            "Classification": 2,
            "operatorSequence": [
                  {
                        "function": "adjoint",
                        "params": [
                              "input"
                        ],
                        "ReturnSequence": {
                              "return": "torch.transpose(input, 1, 0).conj()"
                        }
                  }
            ]
      },
      "torch.argwhere": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "target_api": "paddle.nonzero"
      },
      "torch.dsplit": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "target_api": "paddle.spilt",
            "params_change": {
                  "indices_or_sections": "num_or_sections"
            }
      },
      "torch.column_stack": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "target_api": "paddle.stack",
            "default_kwargs": {
                  "axis": "1"
            }
      },
      "torch.dstack": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "target_api": "paddle.stack",
            "default_kwargs": {
                  "axis": "2"
            }
      },
      "torch.hsplit": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "target_api": "paddle.spilt",
            "params_change": {
                  "indices_or_sections": "num_or_sections"
            },
            "default_kwargs": {
                  "axis": "1"
            }
      },
      "torch.hstack": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "target_api": "paddle.concat",
            "default_kwargs": {
                  "axis": "1"
            }
      },
      "torch.index_add": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.index_add_": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "target_api": "paddle.index_add"
      },
      "torch.index_copy": {
            "Matcher": "OCSMatcher",
            "Classification": 2,
            "operatorSequence": [
                  {
                        "function": "adjoint",
                        "params": [
                              "input",
                              "dim",
                              "index",
                              "source",
                              "reduce"
                        ],
                        "ReturnSequence": {
                              "return": "result",
                              "result": "for i, idx in enumerate(index):\n    input[idx] += source[i]"
                        }
                  }
            ]
      },
      "torch.index_reduce": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.movedim": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "target_api": "paddle.moveaxis"
      },
      "torch.moveaxis": {
            "Matcher": "DirectMatcher",
            "Classification": 0
      },
      "torch.row_stack": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "target_api": "paddle.concat",
            "default_kwargs": {
                  "axis": "0"
            }
      },
      "torch.scatter": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "params_change": {
                  "src": "updates"
            }
      },
      "torch.sinc": {
            "Matcher": "OCSMatcher",
            "Classification": 2,
            "operatorSequence": [
                  {
                        "function": "sinc_kernel",
                        "params": [
                              "iter",
                              "a"
                        ],
                        "ReturnSequence": {
                              "return": "sin(product) / product",
                              "product": "a"
                        }
                  }
            ]
      },
      "torch.Tensor.scatter_": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "params_change": {
                  "src": "updates"
            },
            "target_api": "paddle.scatter"
      },
      "torch.Tensor.scatter_add": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "params_change": {
                  "src": "updates"
            },
            "target_api": "paddle.scatter",
            "default_kwargs": {
                  "reduce": "add"
            }
      },
      "torch.Tensor.scatter_add_": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "params_change": {
                  "src": "updates"
            },
            "target_api": "paddle.scatter",
            "default_kwargs": {
                  "reduce": "add"
            }
      },
      "torch.Tensor.short": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "default_kwargs": {
                  "dtype": "int16"
            }
      },
      "torch.Tensor.int": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "default_kwargs": {
                  "dtype": "int16"
            }
      },
      "torch.Tensor.sigmoid": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "target_api": "paddle.nn.functional.sigmoid"
      },
      "torch.special.expit": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "target_api": "paddle.nn.functional.sigmoid"
      },
      "torch.signbit": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "target_api": "paddle.less",
            "default_kwargs": {
                  "y": "0"
            }
      },
      "torch.Tensor.rsqrt_": {
            "Matcher": "DirectMatcher",
            "Classification": 0,
            "target_api": "paddle.rsqrt"
      },
      "torch.true_divide": {
            "Matcher": "DirectMatcher",
            "classification": 0,
            "target_api": "paddle.div"
      },
      "torch.inverse": {
            "Matcher": "DirectMatcher",
            "classification": 0
      },
      "torch.mv": {
            "Matcher": "DirectMatcher",
            "classification": 0
      },
      "torch.swapdims": {
            "Matcher": "DirectMatcher",
            "classification": 0,
            "target_api": "paddle.transpose"
      },
      "torch.initial_seed": {
            "Matcher": "DirectMatcher",
            "classification": 0,
            "target_api": "paddle.seed"
      },
      "torch.normal": {
            "Matcher": "DirectMatcher",
            "classification": 0
      },
      "torch.get_num_threads": {
            "Matcher": "DirectMatcher",
            "classification": 0,
            "target_api": "os.getenv",
            "default_kwargs": {
                  "key": "OMP_NUM_THREADS"
            }
      },
      "torchvision.datasets.LSUN": {
            "Matcher": "DirectMatcher",
            "classification": 0,
            "target_api": "paddle.vision.datasets.LSUN"
      },
      "torchvision.datasets.lmageFolder": {
            "Matcher": "DirectMatcher",
            "classification": 0,
            "target_api": "paddle.vision.datasets.ImageFolder"
      },
      "torchvision.transforms.Compose": {
            "Matcher": "DirectMatcher",
            "classification": 0,
            "target_api": "paddle.vision.datasets.ImageFolder"
      },
      "torch.backends.cudnn.benchmark": {
            "Matcher": "DirectMatcher",
            "classification": 0,
            "target_api": "paddle.device.cuda.cudnn_benchmark"
      },
      "torchvision.transforms.Normalize": {
            "Matcher": "DirectMatcher",
            "classification": 0,
            "target_api": "paddle.vision.transforms.Normalize"
      },
      "torchvision.transforms.CenterCrop": {
            "Matcher": "DirectMatcher",
            "classification": 0,
            "target_api": "paddle.vision.transforms.CenterCrop"
      },
      "torchvision.datasets.FakeData": {
            "Matcher": "Unsupported",
            "Classification": -1,
            "Issue": "No single or combined operator equivalent available"
      },
      "torch.nn.parallel.DataParallel": {
            "Matcher": "DirectMatcher",
            "classification": 0,
            "target_api": "paddle.DataParallel"
      },
      "torchvision.utils.save_image": {
            "Matcher": "DirectMatcher",
            "classification": 0,
            "target_api": "paddle.vision.utils.save_image"
      },
      "torch.utils.data.DataLoader": {
            "Matcher": "DirectMatcher",
            "classification": 0,
            "target_api": "paddle.io.DataLoader"
      },
      "torchvision.transforms.ToTensor": {
            "Matcher": "DirectMatcher",
            "classification": 0,
            "target_api": "paddle.vision.transforms.ToTensor"
      },
      "torchvision.transforms.Resize": {
            "Matcher": "DirectMatcher",
            "classification": 0,
            "target_api": "paddle.vision.transforms.Resize"
      }
}
